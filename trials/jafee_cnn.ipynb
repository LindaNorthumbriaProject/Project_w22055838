{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m3/6\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.1285 - loss: 1.9890 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - accuracy: 0.1233 - loss: 1.9970 - val_accuracy: 0.0930 - val_loss: 1.9619\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.1632 - loss: 1.9323 - val_accuracy: 0.1163 - val_loss: 1.9462\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2648 - loss: 1.9123 - val_accuracy: 0.3023 - val_loss: 1.9400\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3913 - loss: 1.8578 - val_accuracy: 0.2093 - val_loss: 1.9269\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3594 - loss: 1.7929 - val_accuracy: 0.2791 - val_loss: 1.9488\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3742 - loss: 1.6626 - val_accuracy: 0.2558 - val_loss: 1.8956\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3991 - loss: 1.6191 - val_accuracy: 0.3023 - val_loss: 1.8014\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4219 - loss: 1.4923 - val_accuracy: 0.4186 - val_loss: 1.7214\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.5520 - loss: 1.3837 - val_accuracy: 0.3023 - val_loss: 1.5869\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.5213 - loss: 1.2591 - val_accuracy: 0.4186 - val_loss: 1.6702\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.4186 - loss: 1.6702\n",
      "\u001B[1m2/2\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "Test Accuracy: 41.86%\n",
      "Precision: 0.93\n",
      "Recall: 1.00\n",
      "F1 Score: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = r'/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and extract labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            image_file = os.path.join(folder, filename)\n",
    "            img = Image.open(image_file).convert('L')  # Convert to grayscale\n",
    "            img = img.resize((64, 64))  # Resize to 64x64 for consistency\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(img_array)\n",
    "            label_code = filename.split('.')[1][:2]\n",
    "            labels.append(label_map[label_code])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load images and labels\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape for CNN input\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(64, 64, 1)),  # Input layer for 64x64 grayscale images\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu'),  # First convolution layer\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # First pooling layer\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),  # Second convolution layer\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Second pooling layer\n",
    "    Flatten(),  # Flatten the output for the dense layer\n",
    "    Dense(100, activation='relu'),  # Fully connected layer\n",
    "    Dense(len(np.unique(labels_encoded)), activation='softmax')  # Output layer with one neuron per class\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define data augmentation configuration\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "# Fit the data generator to the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Train the model using the augmented data\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model and calculate precision, recall, and F1-score\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "precision = tf.keras.metrics.Precision()\n",
    "precision.update_state(true_classes, predicted_classes)\n",
    "recall = tf.keras.metrics.Recall()\n",
    "recall.update_state(true_classes, predicted_classes)\n",
    "f1_score = 2 * (precision.result().numpy() * recall.result().numpy()) / (precision.result().numpy() + recall.result().numpy())\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"Precision: {precision.result().numpy():.2f}\")\n",
    "print(f\"Recall: {recall.result().numpy():.2f}\")\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T23:13:23.478821Z",
     "start_time": "2024-08-08T23:13:19.363473Z"
    }
   },
   "id": "233ea43029aa8143"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T23:12:26.940927Z",
     "start_time": "2024-08-08T23:12:26.936739Z"
    }
   },
   "id": "71c07cba99f0a1c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-08T23:12:26.936875Z"
    }
   },
   "id": "22bc19ccd337cba1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-08T23:12:26.937242Z"
    }
   },
   "id": "2049a0040801de2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-08T23:12:26.938520Z"
    }
   },
   "id": "d93da4e7e1da54c4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T23:12:27.136449Z",
     "start_time": "2024-08-08T23:12:27.130859Z"
    }
   },
   "id": "7572704b44ae5677"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.0803 - loss: 3.2312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 56ms/step - accuracy: 0.0758 - loss: 3.2444 - val_accuracy: 0.0930 - val_loss: 2.1852\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.1796 - loss: 2.1157 - val_accuracy: 0.0930 - val_loss: 1.9967\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.1463 - loss: 1.9965 - val_accuracy: 0.0465 - val_loss: 1.9734\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1730 - loss: 1.9414 - val_accuracy: 0.0233 - val_loss: 1.9576\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2464 - loss: 1.9340 - val_accuracy: 0.1395 - val_loss: 2.0398\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1717 - loss: 1.9830 - val_accuracy: 0.2558 - val_loss: 1.9698\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2094 - loss: 1.9383 - val_accuracy: 0.2093 - val_loss: 1.9739\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1837 - loss: 1.9215 - val_accuracy: 0.0930 - val_loss: 1.9793\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1114 - loss: 1.9319 - val_accuracy: 0.2093 - val_loss: 1.9647\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1779 - loss: 1.9247 - val_accuracy: 0.1163 - val_loss: 1.9749\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1163 - loss: 1.9749\n",
      "Configuration: {'filters': [32], 'dense_units': [100], 'dropout': 0.5}\n",
      "Test Accuracy: 11.63%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1823 - loss: 2.2198 - val_accuracy: 0.1163 - val_loss: 1.9476\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.0976 - loss: 1.9993 - val_accuracy: 0.1628 - val_loss: 2.0695\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1585 - loss: 1.9517 - val_accuracy: 0.1860 - val_loss: 1.9665\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2459 - loss: 1.8806 - val_accuracy: 0.1860 - val_loss: 1.9435\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2091 - loss: 1.8805 - val_accuracy: 0.2791 - val_loss: 1.8824\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2719 - loss: 1.8138 - val_accuracy: 0.3953 - val_loss: 1.8499\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.3512 - loss: 1.7632 - val_accuracy: 0.2326 - val_loss: 1.8568\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.3759 - loss: 1.6682 - val_accuracy: 0.2326 - val_loss: 1.8307\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4114 - loss: 1.6160 - val_accuracy: 0.3023 - val_loss: 1.7368\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4238 - loss: 1.5249 - val_accuracy: 0.3256 - val_loss: 1.7597\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3256 - loss: 1.7597\n",
      "Configuration: {'filters': [32], 'dense_units': [100, 200], 'dropout': 0.5}\n",
      "Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - accuracy: 0.1782 - loss: 1.9592 - val_accuracy: 0.0930 - val_loss: 1.9774\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.1460 - loss: 1.9599 - val_accuracy: 0.1163 - val_loss: 1.9598\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1508 - loss: 1.9435 - val_accuracy: 0.0930 - val_loss: 1.9572\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.1597 - loss: 1.9382 - val_accuracy: 0.1395 - val_loss: 1.9608\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2329 - loss: 1.9369 - val_accuracy: 0.1860 - val_loss: 1.9570\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3103 - loss: 1.9044 - val_accuracy: 0.1860 - val_loss: 1.9645\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2216 - loss: 1.8943 - val_accuracy: 0.2326 - val_loss: 1.9359\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3686 - loss: 1.8190 - val_accuracy: 0.2093 - val_loss: 1.9254\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3579 - loss: 1.7802 - val_accuracy: 0.1628 - val_loss: 1.8982\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.4235 - loss: 1.6712 - val_accuracy: 0.2558 - val_loss: 1.8439\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.2558 - loss: 1.8439\n",
      "Configuration: {'filters': [32, 64], 'dense_units': [100, 200], 'dropout': 0.3}\n",
      "Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - accuracy: 0.1466 - loss: 2.1876 - val_accuracy: 0.1395 - val_loss: 2.0313\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1355 - loss: 1.9934 - val_accuracy: 0.2093 - val_loss: 1.9310\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2040 - loss: 1.9496 - val_accuracy: 0.2093 - val_loss: 1.9273\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1678 - loss: 1.9377 - val_accuracy: 0.0930 - val_loss: 1.9491\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1885 - loss: 1.9546 - val_accuracy: 0.1395 - val_loss: 1.9356\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1510 - loss: 1.9376 - val_accuracy: 0.0930 - val_loss: 1.9403\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1294 - loss: 1.9328 - val_accuracy: 0.0930 - val_loss: 1.9352\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1866 - loss: 1.9171 - val_accuracy: 0.1395 - val_loss: 1.9272\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2628 - loss: 1.8887 - val_accuracy: 0.2093 - val_loss: 1.9069\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2758 - loss: 1.8853 - val_accuracy: 0.0930 - val_loss: 1.9127\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.0930 - loss: 1.9127\n",
      "Configuration: {'filters': [32], 'dense_units': [100, 200], 'dropout': 0.3}\n",
      "Test Accuracy: 9.30%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 43ms/step - accuracy: 0.1481 - loss: 1.9713 - val_accuracy: 0.1395 - val_loss: 1.9393\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1489 - loss: 1.9557 - val_accuracy: 0.1395 - val_loss: 1.9486\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2076 - loss: 1.9302 - val_accuracy: 0.1628 - val_loss: 1.9512\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.2309 - loss: 1.9160 - val_accuracy: 0.1860 - val_loss: 1.9617\n",
      "Epoch 5/10\n",
      "\u001B[1m1/6\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 59ms/step - accuracy: 0.2500 - loss: 1.8720Failed configuration {'filters': [32, 64], 'dense_units': [100, 200], 'dropout': 0.3}: Graph execution error:\n",
      "\n",
      "Detected at node adam/Mul_15 defined at (most recent call last):\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "\n",
      "  File \"/var/folders/nt/vmygtqvs10vb28qdjwspykv00000gn/T/ipykernel_4684/27488931.py\", line 94, in <module>\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 69, in train_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 148, in update_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 5463, in multiply\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/sparse.py\", line 627, in sparse_wrapper\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 497, in multiply\n",
      "\n",
      "Incompatible shapes: [64] vs. [0]\n",
      "\t [[{{node adam/Mul_15}}]] [Op:__inference_one_step_on_iterator_75833]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 00:35:21.069026: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [64] vs. [0]\n",
      "\t [[{{function_node __inference_one_step_on_data_75754}}{{node adam/Mul_15}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 56ms/step - accuracy: 0.1014 - loss: 1.9646 - val_accuracy: 0.1163 - val_loss: 1.9571\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1807 - loss: 1.9424 - val_accuracy: 0.1395 - val_loss: 1.9656\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1052 - loss: 1.9537 - val_accuracy: 0.0930 - val_loss: 1.9587\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.1296 - loss: 1.9375 - val_accuracy: 0.0930 - val_loss: 1.9594\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1112 - loss: 1.9511 - val_accuracy: 0.0930 - val_loss: 1.9599\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0969 - loss: 1.9482 - val_accuracy: 0.1163 - val_loss: 1.9560\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1672 - loss: 1.9471 - val_accuracy: 0.1395 - val_loss: 1.9538\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1445 - loss: 1.9414 - val_accuracy: 0.1395 - val_loss: 1.9601\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2539 - loss: 1.9228 - val_accuracy: 0.1395 - val_loss: 1.9805\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1401 - loss: 1.9321 - val_accuracy: 0.0930 - val_loss: 1.9905\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.0930 - loss: 1.9905\n",
      "Configuration: {'filters': [32, 64, 128], 'dense_units': [100, 200], 'dropout': 0.5}\n",
      "Test Accuracy: 9.30%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - accuracy: 0.1614 - loss: 1.9652 - val_accuracy: 0.1395 - val_loss: 1.9448\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.1503 - loss: 1.9469 - val_accuracy: 0.1163 - val_loss: 1.9555\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.1511 - loss: 1.9397 - val_accuracy: 0.0930 - val_loss: 1.9541\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.2310 - loss: 1.9374 - val_accuracy: 0.1395 - val_loss: 1.9620\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2500 - loss: 1.9436 - val_accuracy: 0.2093 - val_loss: 1.9555\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2432 - loss: 1.9160 - val_accuracy: 0.1628 - val_loss: 1.9915\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.2822 - loss: 1.8936 - val_accuracy: 0.1395 - val_loss: 1.9874\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2881 - loss: 1.8581 - val_accuracy: 0.1628 - val_loss: 1.9738\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3112 - loss: 1.8326 - val_accuracy: 0.1628 - val_loss: 1.9557\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3162 - loss: 1.7913 - val_accuracy: 0.1628 - val_loss: 1.9492\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.1628 - loss: 1.9492\n",
      "Configuration: {'filters': [32, 64, 128], 'dense_units': [100], 'dropout': 0.3}\n",
      "Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - accuracy: 0.1523 - loss: 2.0670 - val_accuracy: 0.1628 - val_loss: 1.9459\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1875 - loss: 1.9448 - val_accuracy: 0.1163 - val_loss: 1.9539\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1632 - loss: 1.9268 - val_accuracy: 0.1628 - val_loss: 1.9512\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3009 - loss: 1.8997 - val_accuracy: 0.1395 - val_loss: 1.9533\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2805 - loss: 1.8948 - val_accuracy: 0.1860 - val_loss: 1.9320\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2524 - loss: 1.8539 - val_accuracy: 0.2093 - val_loss: 1.9360\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2763 - loss: 1.8130 - val_accuracy: 0.2093 - val_loss: 1.9771\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2792 - loss: 1.7754 - val_accuracy: 0.2326 - val_loss: 1.9588\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4095 - loss: 1.6600 - val_accuracy: 0.2558 - val_loss: 1.9320\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.2947 - loss: 1.7021 - val_accuracy: 0.3488 - val_loss: 1.8545\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3488 - loss: 1.8545\n",
      "Configuration: {'filters': [32, 64], 'dense_units': [100], 'dropout': 0.3}\n",
      "Test Accuracy: 34.88%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1555 - loss: 2.7484 - val_accuracy: 0.1395 - val_loss: 2.2183\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1742 - loss: 2.2136 - val_accuracy: 0.1860 - val_loss: 1.9671\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2046 - loss: 1.9365 - val_accuracy: 0.1628 - val_loss: 1.9729\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2006 - loss: 1.8935 - val_accuracy: 0.0930 - val_loss: 1.9558\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1631 - loss: 1.9338 - val_accuracy: 0.1628 - val_loss: 1.9297\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2534 - loss: 1.8930 - val_accuracy: 0.1860 - val_loss: 1.9183\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2170 - loss: 1.8865 - val_accuracy: 0.1860 - val_loss: 1.9119\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2677 - loss: 1.8525 - val_accuracy: 0.2326 - val_loss: 1.9188\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2023 - loss: 1.8577 - val_accuracy: 0.2326 - val_loss: 1.9244\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2688 - loss: 1.8132 - val_accuracy: 0.2791 - val_loss: 1.8598\n",
      "2/2 - 0s - 6ms/step - accuracy: 0.2791 - loss: 1.8598\n",
      "Configuration: {'filters': [32], 'dense_units': [100], 'dropout': 0.5}\n",
      "Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - accuracy: 0.1799 - loss: 1.9629 - val_accuracy: 0.0930 - val_loss: 1.9753\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1699 - loss: 1.9380 - val_accuracy: 0.1628 - val_loss: 1.9530\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1460 - loss: 1.9472 - val_accuracy: 0.0930 - val_loss: 1.9509\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1819 - loss: 1.9370 - val_accuracy: 0.2326 - val_loss: 1.9641\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1356 - loss: 1.9457 - val_accuracy: 0.1628 - val_loss: 1.9618\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.2154 - loss: 1.9261 - val_accuracy: 0.1860 - val_loss: 1.9717\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2239 - loss: 1.9160 - val_accuracy: 0.1628 - val_loss: 1.9587\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.2440 - loss: 1.9182 - val_accuracy: 0.2093 - val_loss: 1.9400\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2727 - loss: 1.8647 - val_accuracy: 0.1628 - val_loss: 1.9513\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.1930 - loss: 1.8714 - val_accuracy: 0.1395 - val_loss: 1.9301\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.1395 - loss: 1.9301\n",
      "Configuration: {'filters': [32, 64, 128], 'dense_units': [100], 'dropout': 0.5}\n",
      "Test Accuracy: 13.95%\n",
      "Best Configuration: {'filters': [32, 64], 'dense_units': [100], 'dropout': 0.3}\n",
      "Best Test Accuracy: 34.88%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            if filename.endswith('.tiff'):\n",
    "                image_file = os.path.join(folder, filename)\n",
    "                img = Image.open(image_file).convert('L')\n",
    "                img = img.resize((64, 64))\n",
    "                img_array = np.array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                label_code = filename.split('.')[1][:2]\n",
    "                labels.append(label_map[label_code])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define data augmentation configuration\n",
    "datagen = ImageDataGenerator(shear_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Generate configurations function\n",
    "def generate_configurations(num_configs):\n",
    "    configurations = []\n",
    "    for i in range(num_configs):\n",
    "        config = {\n",
    "            'filters': [32 * 2**j for j in range(random.randint(1, 3))], # 1-3 layers with increasing filter size\n",
    "            'dense_units': [100 * 2**j for j in range(random.randint(1, 2))], # 1-2 dense layers with increasing units\n",
    "            'dropout': random.choice([0.3, 0.5]), # Random dropout of 0.3 or 0.5\n",
    "        }\n",
    "        configurations.append(config)\n",
    "    return configurations\n",
    "\n",
    "configurations = generate_configurations(10) # Generate 10 random configurations\n",
    "best_configuration = {}\n",
    "best_accuracy = 0\n",
    "\n",
    "# Training and evaluating models\n",
    "for config in configurations:\n",
    "    try:\n",
    "        model = Sequential([InputLayer(input_shape=(64, 64, 1))])\n",
    "        for filters in config['filters']:\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        for units in config['dense_units']:\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(config['dropout']))\n",
    "        model.add(Dense(len(np.unique(labels_encoded)), activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_test, y_test), epochs=10, verbose=1)\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "        print(f\"Configuration: {config}\")\n",
    "        print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "        if test_acc > best_accuracy:\n",
    "            best_accuracy = test_acc\n",
    "            best_configuration = config\n",
    "    except Exception as e:\n",
    "        print(f\"Failed configuration {config}: {e}\")\n",
    "\n",
    "# Output best results\n",
    "print(f\"Best Configuration: {best_configuration}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T23:35:35.167315Z",
     "start_time": "2024-08-08T23:35:08.260875Z"
    }
   },
   "id": "d2762e554090448"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3/6\u001B[0m \u001B[32m━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1215 - loss: 2.3818 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - accuracy: 0.1240 - loss: 2.5251 - val_accuracy: 0.1395 - val_loss: 2.1199\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1623 - loss: 2.2872 - val_accuracy: 0.1395 - val_loss: 1.9509\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1937 - loss: 1.9485 - val_accuracy: 0.1860 - val_loss: 2.0324\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2889 - loss: 1.8480 - val_accuracy: 0.2093 - val_loss: 1.8713\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3574 - loss: 1.7697 - val_accuracy: 0.3488 - val_loss: 1.8065\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3964 - loss: 1.7007 - val_accuracy: 0.2558 - val_loss: 1.8083\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4594 - loss: 1.6399 - val_accuracy: 0.2791 - val_loss: 1.7521\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4412 - loss: 1.5765 - val_accuracy: 0.3721 - val_loss: 1.6981\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5965 - loss: 1.4057 - val_accuracy: 0.3953 - val_loss: 1.6562\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.5099 - loss: 1.3735 - val_accuracy: 0.3721 - val_loss: 1.5686\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3721 - loss: 1.5686\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 37.21%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - accuracy: 0.1812 - loss: 2.5676 - val_accuracy: 0.0930 - val_loss: 2.0821\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1982 - loss: 2.2823 - val_accuracy: 0.0930 - val_loss: 2.0007\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1907 - loss: 1.9748 - val_accuracy: 0.2093 - val_loss: 1.9824\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1478 - loss: 1.9350 - val_accuracy: 0.1628 - val_loss: 1.9365\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2257 - loss: 1.8472 - val_accuracy: 0.1860 - val_loss: 1.9191\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2509 - loss: 1.8199 - val_accuracy: 0.2791 - val_loss: 1.8820\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2798 - loss: 1.7736 - val_accuracy: 0.2326 - val_loss: 1.8752\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3826 - loss: 1.7216 - val_accuracy: 0.2093 - val_loss: 1.8760\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3586 - loss: 1.6574 - val_accuracy: 0.2326 - val_loss: 1.8407\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3947 - loss: 1.7023 - val_accuracy: 0.3256 - val_loss: 1.7776\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3256 - loss: 1.7776\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - accuracy: 0.1228 - loss: 2.5393 - val_accuracy: 0.2326 - val_loss: 2.1507\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1862 - loss: 2.1671 - val_accuracy: 0.1395 - val_loss: 2.1411\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.2546 - loss: 1.9302 - val_accuracy: 0.1860 - val_loss: 2.0969\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3322 - loss: 1.7666 - val_accuracy: 0.1628 - val_loss: 1.9312\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3084 - loss: 1.6847 - val_accuracy: 0.2093 - val_loss: 1.9434\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.4078 - loss: 1.7233 - val_accuracy: 0.3256 - val_loss: 1.7928\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4588 - loss: 1.5670 - val_accuracy: 0.3256 - val_loss: 1.7587\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.5695 - loss: 1.4477 - val_accuracy: 0.3953 - val_loss: 1.7537\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.5698 - loss: 1.3051 - val_accuracy: 0.4419 - val_loss: 1.6165\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.5769 - loss: 1.2435 - val_accuracy: 0.4419 - val_loss: 1.5714\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.4419 - loss: 1.5714\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 44.19%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - accuracy: 0.1530 - loss: 2.8521 - val_accuracy: 0.2558 - val_loss: 2.2670\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.1896 - loss: 2.4778 - val_accuracy: 0.0930 - val_loss: 2.0306\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1590 - loss: 2.0409 - val_accuracy: 0.1628 - val_loss: 2.0246\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1988 - loss: 1.9284 - val_accuracy: 0.1395 - val_loss: 1.9514\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2375 - loss: 1.9244 - val_accuracy: 0.0698 - val_loss: 1.9398\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2508 - loss: 1.8311 - val_accuracy: 0.1628 - val_loss: 1.9284\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3085 - loss: 1.8141 - val_accuracy: 0.1860 - val_loss: 1.9475\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2907 - loss: 1.7848 - val_accuracy: 0.1163 - val_loss: 1.9505\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.2825 - loss: 1.7656 - val_accuracy: 0.2558 - val_loss: 1.9115\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.2908 - loss: 1.7396 - val_accuracy: 0.2791 - val_loss: 1.8752\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.2791 - loss: 1.8752\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1257 - loss: 2.3636 - val_accuracy: 0.0930 - val_loss: 2.3348\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1312 - loss: 2.2341 - val_accuracy: 0.1395 - val_loss: 2.0102\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2157 - loss: 1.8764 - val_accuracy: 0.1860 - val_loss: 1.9305\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2145 - loss: 1.8784 - val_accuracy: 0.2093 - val_loss: 1.8983\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2886 - loss: 1.8334 - val_accuracy: 0.1860 - val_loss: 1.9104\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3021 - loss: 1.8199 - val_accuracy: 0.3023 - val_loss: 1.8426\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3797 - loss: 1.6721 - val_accuracy: 0.2558 - val_loss: 1.8439\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4625 - loss: 1.5760 - val_accuracy: 0.2326 - val_loss: 1.8532\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4462 - loss: 1.5242 - val_accuracy: 0.3023 - val_loss: 1.7428\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5129 - loss: 1.4580 - val_accuracy: 0.3256 - val_loss: 1.6973\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3256 - loss: 1.6973\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - accuracy: 0.1069 - loss: 2.8221 - val_accuracy: 0.1395 - val_loss: 1.9964\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1883 - loss: 2.0674 - val_accuracy: 0.0930 - val_loss: 1.9669\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1961 - loss: 1.9478 - val_accuracy: 0.1860 - val_loss: 1.9492\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2400 - loss: 1.9252 - val_accuracy: 0.2093 - val_loss: 1.9765\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2014 - loss: 1.9312 - val_accuracy: 0.2326 - val_loss: 1.9118\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2314 - loss: 1.8892 - val_accuracy: 0.1860 - val_loss: 1.9222\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2466 - loss: 1.8721 - val_accuracy: 0.3256 - val_loss: 1.8897\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2993 - loss: 1.8340 - val_accuracy: 0.1860 - val_loss: 1.9028\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2077 - loss: 1.8639 - val_accuracy: 0.1860 - val_loss: 1.8953\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3582 - loss: 1.8093 - val_accuracy: 0.3023 - val_loss: 1.8346\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3023 - loss: 1.8346\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 53ms/step - accuracy: 0.1117 - loss: 2.5076 - val_accuracy: 0.1163 - val_loss: 2.0698\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1805 - loss: 2.0780 - val_accuracy: 0.1163 - val_loss: 1.9262\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.2122 - loss: 1.9030 - val_accuracy: 0.2558 - val_loss: 1.9205\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2661 - loss: 1.8954 - val_accuracy: 0.1860 - val_loss: 1.9111\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.3059 - loss: 1.8530 - val_accuracy: 0.3721 - val_loss: 1.8293\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.3814 - loss: 1.7205 - val_accuracy: 0.3023 - val_loss: 1.7865\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3183 - loss: 1.6627 - val_accuracy: 0.3953 - val_loss: 1.7542\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.5529 - loss: 1.5492 - val_accuracy: 0.3488 - val_loss: 1.7257\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.5260 - loss: 1.4436 - val_accuracy: 0.3488 - val_loss: 1.6018\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.5643 - loss: 1.2931 - val_accuracy: 0.4186 - val_loss: 1.5389\n",
      "2/2 - 0s - 10ms/step - accuracy: 0.4186 - loss: 1.5389\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 41.86%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 54ms/step - accuracy: 0.1682 - loss: 2.7105 - val_accuracy: 0.2093 - val_loss: 2.2893\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1677 - loss: 2.0231 - val_accuracy: 0.1860 - val_loss: 1.9445\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1940 - loss: 1.9872 - val_accuracy: 0.2791 - val_loss: 1.9114\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.2493 - loss: 1.8857 - val_accuracy: 0.2093 - val_loss: 1.9134\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.2040 - loss: 1.8289 - val_accuracy: 0.2791 - val_loss: 1.8763\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3367 - loss: 1.7853 - val_accuracy: 0.2558 - val_loss: 1.8815\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.4062 - loss: 1.7304 - val_accuracy: 0.3023 - val_loss: 1.8191\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.3648 - loss: 1.6863 - val_accuracy: 0.4419 - val_loss: 1.7474\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.3766 - loss: 1.6488 - val_accuracy: 0.3488 - val_loss: 1.7307\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.4445 - loss: 1.5405 - val_accuracy: 0.3953 - val_loss: 1.6992\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3953 - loss: 1.6992\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 39.53%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 82ms/step - accuracy: 0.0971 - loss: 2.7920 - val_accuracy: 0.0698 - val_loss: 2.7749\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 70ms/step - accuracy: 0.1495 - loss: 2.6620 - val_accuracy: 0.2326 - val_loss: 1.9550\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - accuracy: 0.2206 - loss: 1.9126 - val_accuracy: 0.3953 - val_loss: 1.8416\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - accuracy: 0.3298 - loss: 1.7361 - val_accuracy: 0.1860 - val_loss: 1.8272\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - accuracy: 0.3778 - loss: 1.6714 - val_accuracy: 0.3488 - val_loss: 1.7742\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - accuracy: 0.4797 - loss: 1.5460 - val_accuracy: 0.3256 - val_loss: 1.7031\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step - accuracy: 0.4902 - loss: 1.4288 - val_accuracy: 0.3953 - val_loss: 1.6941\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step - accuracy: 0.5818 - loss: 1.2253 - val_accuracy: 0.3721 - val_loss: 1.5587\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step - accuracy: 0.6436 - loss: 1.1164 - val_accuracy: 0.4419 - val_loss: 1.5625\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - accuracy: 0.7377 - loss: 1.0376 - val_accuracy: 0.3953 - val_loss: 1.4364\n",
      "2/2 - 0s - 15ms/step - accuracy: 0.3953 - loss: 1.4364\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 39.53%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 82ms/step - accuracy: 0.1365 - loss: 4.7292 - val_accuracy: 0.2558 - val_loss: 2.8856\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step - accuracy: 0.2275 - loss: 2.7896 - val_accuracy: 0.1860 - val_loss: 1.9827\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - accuracy: 0.2707 - loss: 1.9747 - val_accuracy: 0.0930 - val_loss: 2.0316\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step - accuracy: 0.1758 - loss: 1.9394 - val_accuracy: 0.0698 - val_loss: 1.9529\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 79ms/step - accuracy: 0.1477 - loss: 1.9306 - val_accuracy: 0.1860 - val_loss: 1.9437\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 70ms/step - accuracy: 0.1532 - loss: 1.8974 - val_accuracy: 0.1395 - val_loss: 1.9414\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - accuracy: 0.2631 - loss: 1.8534 - val_accuracy: 0.2326 - val_loss: 1.9526\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step - accuracy: 0.2817 - loss: 1.7795 - val_accuracy: 0.2791 - val_loss: 1.9279\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step - accuracy: 0.3141 - loss: 1.8189 - val_accuracy: 0.3023 - val_loss: 1.8753\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step - accuracy: 0.2481 - loss: 1.7705 - val_accuracy: 0.2093 - val_loss: 1.8793\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.2093 - loss: 1.8793\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 54ms/step - accuracy: 0.1270 - loss: 3.0225 - val_accuracy: 0.2326 - val_loss: 2.2260\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1562 - loss: 2.2894 - val_accuracy: 0.1628 - val_loss: 2.0146\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.2434 - loss: 1.8689 - val_accuracy: 0.1628 - val_loss: 1.9316\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2295 - loss: 1.8753 - val_accuracy: 0.1395 - val_loss: 2.0136\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2616 - loss: 1.8209 - val_accuracy: 0.2326 - val_loss: 1.9397\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.3448 - loss: 1.7454 - val_accuracy: 0.2558 - val_loss: 1.9558\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.4066 - loss: 1.7139 - val_accuracy: 0.3721 - val_loss: 1.8947\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3661 - loss: 1.7037 - val_accuracy: 0.3488 - val_loss: 1.8631\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.4033 - loss: 1.6232 - val_accuracy: 0.3256 - val_loss: 1.8440\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.4782 - loss: 1.5465 - val_accuracy: 0.3721 - val_loss: 1.7534\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3721 - loss: 1.7534\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 37.21%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 52ms/step - accuracy: 0.1752 - loss: 2.4416 - val_accuracy: 0.1395 - val_loss: 2.2002\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1609 - loss: 2.3960 - val_accuracy: 0.1628 - val_loss: 1.9302\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2325 - loss: 1.9011 - val_accuracy: 0.1860 - val_loss: 1.9130\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2733 - loss: 1.8322 - val_accuracy: 0.2093 - val_loss: 1.8637\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2917 - loss: 1.7802 - val_accuracy: 0.2791 - val_loss: 1.8589\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.3071 - loss: 1.7375 - val_accuracy: 0.2093 - val_loss: 1.8138\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.3849 - loss: 1.6919 - val_accuracy: 0.3488 - val_loss: 1.7327\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.4162 - loss: 1.5052 - val_accuracy: 0.3023 - val_loss: 1.6881\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.3946 - loss: 1.5385 - val_accuracy: 0.3256 - val_loss: 1.6353\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.4236 - loss: 1.4561 - val_accuracy: 0.3023 - val_loss: 1.5719\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3023 - loss: 1.5719\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - accuracy: 0.1458 - loss: 2.5868 - val_accuracy: 0.1860 - val_loss: 2.0316\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1643 - loss: 1.9451 - val_accuracy: 0.1163 - val_loss: 1.9891\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2250 - loss: 1.9333 - val_accuracy: 0.0930 - val_loss: 1.9990\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1862 - loss: 1.8735 - val_accuracy: 0.2326 - val_loss: 1.9892\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2736 - loss: 1.8471 - val_accuracy: 0.3023 - val_loss: 1.9022\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3160 - loss: 1.8213 - val_accuracy: 0.2326 - val_loss: 1.8971\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3232 - loss: 1.7963 - val_accuracy: 0.2326 - val_loss: 1.8917\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3058 - loss: 1.7790 - val_accuracy: 0.3256 - val_loss: 1.8470\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.3919 - loss: 1.6701 - val_accuracy: 0.1860 - val_loss: 1.8501\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4197 - loss: 1.5907 - val_accuracy: 0.3256 - val_loss: 1.8236\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3256 - loss: 1.8236\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - accuracy: 0.1137 - loss: 2.5619 - val_accuracy: 0.1628 - val_loss: 1.9499\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1715 - loss: 2.2957 - val_accuracy: 0.1163 - val_loss: 1.9495\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2203 - loss: 1.8787 - val_accuracy: 0.1860 - val_loss: 1.9503\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2165 - loss: 1.8818 - val_accuracy: 0.2093 - val_loss: 1.9198\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2820 - loss: 1.7909 - val_accuracy: 0.1395 - val_loss: 1.9361\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3234 - loss: 1.7454 - val_accuracy: 0.2093 - val_loss: 1.8924\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2321 - loss: 1.7747 - val_accuracy: 0.3256 - val_loss: 1.8849\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.2945 - loss: 1.7233 - val_accuracy: 0.2791 - val_loss: 1.8220\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.2531 - loss: 1.7331 - val_accuracy: 0.3256 - val_loss: 1.8012\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.4242 - loss: 1.5899 - val_accuracy: 0.3023 - val_loss: 1.8026\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3023 - loss: 1.8026\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - accuracy: 0.1579 - loss: 3.1454 - val_accuracy: 0.1395 - val_loss: 2.1946\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1819 - loss: 2.2974 - val_accuracy: 0.1163 - val_loss: 2.0092\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.2287 - loss: 1.9262 - val_accuracy: 0.1860 - val_loss: 2.0013\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.2247 - loss: 1.8991 - val_accuracy: 0.2326 - val_loss: 1.9452\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3266 - loss: 1.7654 - val_accuracy: 0.2093 - val_loss: 1.9072\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.4128 - loss: 1.6615 - val_accuracy: 0.3488 - val_loss: 1.8127\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.5197 - loss: 1.5269 - val_accuracy: 0.3488 - val_loss: 1.7456\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.4720 - loss: 1.4724 - val_accuracy: 0.3953 - val_loss: 1.6529\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.5809 - loss: 1.3726 - val_accuracy: 0.4651 - val_loss: 1.5751\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.6440 - loss: 1.2441 - val_accuracy: 0.3488 - val_loss: 1.5577\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3488 - loss: 1.5577\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 34.88%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - accuracy: 0.1660 - loss: 3.2483 - val_accuracy: 0.1163 - val_loss: 2.2800\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1791 - loss: 2.4732 - val_accuracy: 0.1395 - val_loss: 1.9920\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.1733 - loss: 2.0263 - val_accuracy: 0.1395 - val_loss: 1.9965\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1599 - loss: 1.9943 - val_accuracy: 0.2326 - val_loss: 1.9626\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2450 - loss: 1.8489 - val_accuracy: 0.1860 - val_loss: 1.9052\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2604 - loss: 1.8196 - val_accuracy: 0.2326 - val_loss: 1.9351\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3306 - loss: 1.7700 - val_accuracy: 0.2326 - val_loss: 1.8634\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3921 - loss: 1.6781 - val_accuracy: 0.2558 - val_loss: 1.8563\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.4595 - loss: 1.6625 - val_accuracy: 0.2326 - val_loss: 1.8259\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.4730 - loss: 1.5415 - val_accuracy: 0.3488 - val_loss: 1.7924\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3488 - loss: 1.7924\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 34.88%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1423 - loss: 2.2597 - val_accuracy: 0.0930 - val_loss: 2.1142\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1774 - loss: 2.0396 - val_accuracy: 0.1163 - val_loss: 1.9446\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1428 - loss: 1.9210 - val_accuracy: 0.1395 - val_loss: 1.9745\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2850 - loss: 1.8288 - val_accuracy: 0.1395 - val_loss: 1.9397\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2565 - loss: 1.8372 - val_accuracy: 0.2093 - val_loss: 1.8775\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3322 - loss: 1.7661 - val_accuracy: 0.1860 - val_loss: 1.8790\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.3581 - loss: 1.6503 - val_accuracy: 0.2558 - val_loss: 1.8145\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4587 - loss: 1.5556 - val_accuracy: 0.2326 - val_loss: 1.7630\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.5027 - loss: 1.4521 - val_accuracy: 0.3953 - val_loss: 1.7022\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5039 - loss: 1.3626 - val_accuracy: 0.4186 - val_loss: 1.6340\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.4186 - loss: 1.6340\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 41.86%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - accuracy: 0.1349 - loss: 2.8726 - val_accuracy: 0.1395 - val_loss: 2.1411\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2071 - loss: 2.1342 - val_accuracy: 0.1628 - val_loss: 2.0112\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1961 - loss: 1.9137 - val_accuracy: 0.1395 - val_loss: 1.9665\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2022 - loss: 1.9094 - val_accuracy: 0.1163 - val_loss: 1.9365\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1912 - loss: 1.9032 - val_accuracy: 0.1395 - val_loss: 1.9276\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2663 - loss: 1.8125 - val_accuracy: 0.1628 - val_loss: 1.9310\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2537 - loss: 1.8350 - val_accuracy: 0.2093 - val_loss: 1.9040\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2567 - loss: 1.8630 - val_accuracy: 0.2558 - val_loss: 1.8939\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2917 - loss: 1.7559 - val_accuracy: 0.2093 - val_loss: 1.8743\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2712 - loss: 1.7600 - val_accuracy: 0.2093 - val_loss: 1.8734\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2093 - loss: 1.8734\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - accuracy: 0.1190 - loss: 2.0441 - val_accuracy: 0.0930 - val_loss: 2.0533\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1768 - loss: 2.0855 - val_accuracy: 0.1628 - val_loss: 1.9812\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.1793 - loss: 1.9663 - val_accuracy: 0.1163 - val_loss: 1.9326\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2357 - loss: 1.8761 - val_accuracy: 0.1395 - val_loss: 1.9539\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2433 - loss: 1.8677 - val_accuracy: 0.2791 - val_loss: 1.8836\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3544 - loss: 1.7503 - val_accuracy: 0.1860 - val_loss: 1.8705\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4081 - loss: 1.6271 - val_accuracy: 0.2791 - val_loss: 1.7887\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4038 - loss: 1.6108 - val_accuracy: 0.3256 - val_loss: 1.7286\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5837 - loss: 1.3761 - val_accuracy: 0.3023 - val_loss: 1.6728\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5277 - loss: 1.3689 - val_accuracy: 0.2791 - val_loss: 1.6878\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.2791 - loss: 1.6878\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1010 - loss: 2.0650 - val_accuracy: 0.1163 - val_loss: 2.0065\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1693 - loss: 2.0191 - val_accuracy: 0.1163 - val_loss: 1.9425\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1726 - loss: 1.9377 - val_accuracy: 0.1395 - val_loss: 1.9515\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2012 - loss: 1.8899 - val_accuracy: 0.2093 - val_loss: 1.9544\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2307 - loss: 1.8878 - val_accuracy: 0.1860 - val_loss: 1.9273\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3050 - loss: 1.8282 - val_accuracy: 0.2326 - val_loss: 1.8825\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3387 - loss: 1.7575 - val_accuracy: 0.3023 - val_loss: 1.8557\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3994 - loss: 1.6442 - val_accuracy: 0.3023 - val_loss: 1.7804\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4275 - loss: 1.5583 - val_accuracy: 0.3023 - val_loss: 1.7482\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4868 - loss: 1.4559 - val_accuracy: 0.4651 - val_loss: 1.6218\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.4651 - loss: 1.6218\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 46.51%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - accuracy: 0.1399 - loss: 2.5996 - val_accuracy: 0.0930 - val_loss: 2.2634\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2285 - loss: 2.2918 - val_accuracy: 0.1163 - val_loss: 2.3151\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1440 - loss: 2.1814 - val_accuracy: 0.1628 - val_loss: 1.9329\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1353 - loss: 2.0294 - val_accuracy: 0.2791 - val_loss: 1.8932\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3349 - loss: 1.8408 - val_accuracy: 0.3023 - val_loss: 1.9005\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.2687 - loss: 1.8028 - val_accuracy: 0.2558 - val_loss: 1.8728\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4059 - loss: 1.6981 - val_accuracy: 0.2558 - val_loss: 1.8523\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.4129 - loss: 1.6202 - val_accuracy: 0.2791 - val_loss: 1.7518\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.5096 - loss: 1.5223 - val_accuracy: 0.3256 - val_loss: 1.7409\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.5125 - loss: 1.4088 - val_accuracy: 0.3721 - val_loss: 1.7239\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3721 - loss: 1.7239\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 37.21%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - accuracy: 0.1316 - loss: 2.5135 - val_accuracy: 0.1860 - val_loss: 2.3091\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1290 - loss: 2.4428 - val_accuracy: 0.1628 - val_loss: 1.9397\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.1718 - loss: 2.0452 - val_accuracy: 0.2093 - val_loss: 1.9578\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.1515 - loss: 1.9675 - val_accuracy: 0.1628 - val_loss: 1.9440\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1826 - loss: 1.9155 - val_accuracy: 0.2093 - val_loss: 1.9449\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2909 - loss: 1.8809 - val_accuracy: 0.2558 - val_loss: 1.9486\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3539 - loss: 1.8100 - val_accuracy: 0.2326 - val_loss: 1.9463\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3352 - loss: 1.8005 - val_accuracy: 0.2093 - val_loss: 1.9115\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.2728 - loss: 1.7424 - val_accuracy: 0.3256 - val_loss: 1.8437\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.4296 - loss: 1.6488 - val_accuracy: 0.2558 - val_loss: 1.8204\n",
      "2/2 - 0s - 10ms/step - accuracy: 0.2558 - loss: 1.8204\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - accuracy: 0.1373 - loss: 2.0911 - val_accuracy: 0.1628 - val_loss: 2.2282\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1841 - loss: 2.1623 - val_accuracy: 0.2326 - val_loss: 1.9716\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1545 - loss: 1.9498 - val_accuracy: 0.1860 - val_loss: 1.9156\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1876 - loss: 1.9353 - val_accuracy: 0.2093 - val_loss: 1.9055\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3202 - loss: 1.8171 - val_accuracy: 0.2791 - val_loss: 1.8777\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3146 - loss: 1.7392 - val_accuracy: 0.2093 - val_loss: 1.8398\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3379 - loss: 1.6865 - val_accuracy: 0.3256 - val_loss: 1.8191\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4551 - loss: 1.5316 - val_accuracy: 0.2558 - val_loss: 1.7982\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4667 - loss: 1.5011 - val_accuracy: 0.3023 - val_loss: 1.7206\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4427 - loss: 1.4313 - val_accuracy: 0.3023 - val_loss: 1.6368\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3023 - loss: 1.6368\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1841 - loss: 2.1241 - val_accuracy: 0.0930 - val_loss: 1.9782\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1376 - loss: 2.0651 - val_accuracy: 0.2326 - val_loss: 1.9137\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1091 - loss: 2.0158 - val_accuracy: 0.1860 - val_loss: 1.9487\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1772 - loss: 1.9340 - val_accuracy: 0.1860 - val_loss: 1.9396\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2371 - loss: 1.8971 - val_accuracy: 0.1860 - val_loss: 1.9326\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2359 - loss: 1.8740 - val_accuracy: 0.1860 - val_loss: 1.9188\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.3097 - loss: 1.7613 - val_accuracy: 0.2326 - val_loss: 1.8686\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.2765 - loss: 1.7233 - val_accuracy: 0.2093 - val_loss: 1.8307\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3785 - loss: 1.6306 - val_accuracy: 0.2558 - val_loss: 1.7459\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4728 - loss: 1.4508 - val_accuracy: 0.3023 - val_loss: 1.7123\n",
      "2/2 - 0s - 22ms/step - accuracy: 0.3023 - loss: 1.7123\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 56ms/step - accuracy: 0.1299 - loss: 2.0761 - val_accuracy: 0.0930 - val_loss: 2.0070\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1571 - loss: 2.0784 - val_accuracy: 0.1163 - val_loss: 1.9516\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step - accuracy: 0.1509 - loss: 2.0049 - val_accuracy: 0.1860 - val_loss: 1.9349\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2236 - loss: 1.8685 - val_accuracy: 0.3256 - val_loss: 1.9099\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.3004 - loss: 1.8431 - val_accuracy: 0.2326 - val_loss: 1.8678\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3823 - loss: 1.7144 - val_accuracy: 0.3023 - val_loss: 1.8167\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.3260 - loss: 1.6402 - val_accuracy: 0.3023 - val_loss: 1.7733\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.5025 - loss: 1.4921 - val_accuracy: 0.3488 - val_loss: 1.6340\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.5294 - loss: 1.3176 - val_accuracy: 0.3488 - val_loss: 1.6018\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.4788 - loss: 1.2970 - val_accuracy: 0.3953 - val_loss: 1.5171\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.3953 - loss: 1.5171\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 39.53%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - accuracy: 0.0808 - loss: 2.5703 - val_accuracy: 0.1628 - val_loss: 1.9722\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1356 - loss: 2.0472 - val_accuracy: 0.0930 - val_loss: 1.9346\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1911 - loss: 1.9529 - val_accuracy: 0.0930 - val_loss: 2.0009\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.1819 - loss: 1.9420 - val_accuracy: 0.1395 - val_loss: 1.9451\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.2005 - loss: 1.9493 - val_accuracy: 0.1860 - val_loss: 1.9371\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1909 - loss: 1.9028 - val_accuracy: 0.2558 - val_loss: 1.9263\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.2228 - loss: 1.8857 - val_accuracy: 0.2093 - val_loss: 1.9093\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.3280 - loss: 1.8080 - val_accuracy: 0.2326 - val_loss: 1.8896\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3202 - loss: 1.7716 - val_accuracy: 0.3023 - val_loss: 1.8401\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.3516 - loss: 1.7058 - val_accuracy: 0.3023 - val_loss: 1.8208\n",
      "2/2 - 0s - 10ms/step - accuracy: 0.3023 - loss: 1.8208\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 82ms/step - accuracy: 0.1753 - loss: 2.5622 - val_accuracy: 0.1163 - val_loss: 2.1595\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - accuracy: 0.1403 - loss: 2.1686 - val_accuracy: 0.2326 - val_loss: 1.9878\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - accuracy: 0.1637 - loss: 1.9546 - val_accuracy: 0.0930 - val_loss: 1.9438\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step - accuracy: 0.2705 - loss: 1.8641 - val_accuracy: 0.2093 - val_loss: 1.8997\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - accuracy: 0.3846 - loss: 1.7863 - val_accuracy: 0.1860 - val_loss: 1.9698\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step - accuracy: 0.3729 - loss: 1.6862 - val_accuracy: 0.2326 - val_loss: 1.8623\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step - accuracy: 0.4709 - loss: 1.5418 - val_accuracy: 0.2558 - val_loss: 1.7800\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step - accuracy: 0.5594 - loss: 1.3295 - val_accuracy: 0.3023 - val_loss: 1.6866\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - accuracy: 0.6134 - loss: 1.2031 - val_accuracy: 0.4884 - val_loss: 1.4393\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - accuracy: 0.6656 - loss: 1.0508 - val_accuracy: 0.4186 - val_loss: 1.4743\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.4186 - loss: 1.4743\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 41.86%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 90ms/step - accuracy: 0.0982 - loss: 2.8581 - val_accuracy: 0.1628 - val_loss: 1.9733\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step - accuracy: 0.1556 - loss: 2.3043 - val_accuracy: 0.1860 - val_loss: 1.9604\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 70ms/step - accuracy: 0.1533 - loss: 1.9665 - val_accuracy: 0.2558 - val_loss: 1.9198\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step - accuracy: 0.1623 - loss: 1.9699 - val_accuracy: 0.1628 - val_loss: 1.9495\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step - accuracy: 0.1618 - loss: 1.9457 - val_accuracy: 0.3023 - val_loss: 1.9111\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 99ms/step - accuracy: 0.2852 - loss: 1.8631 - val_accuracy: 0.1860 - val_loss: 1.8880\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step - accuracy: 0.3024 - loss: 1.8183 - val_accuracy: 0.2326 - val_loss: 1.8667\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - accuracy: 0.2982 - loss: 1.7778 - val_accuracy: 0.2791 - val_loss: 1.8262\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step - accuracy: 0.4451 - loss: 1.6693 - val_accuracy: 0.3023 - val_loss: 1.7737\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step - accuracy: 0.4265 - loss: 1.5200 - val_accuracy: 0.3256 - val_loss: 1.6930\n",
      "2/2 - 0s - 10ms/step - accuracy: 0.3256 - loss: 1.6930\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - accuracy: 0.1362 - loss: 2.1459 - val_accuracy: 0.1860 - val_loss: 2.0011\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1228 - loss: 2.0082 - val_accuracy: 0.1163 - val_loss: 1.9333\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1549 - loss: 1.9501 - val_accuracy: 0.1860 - val_loss: 1.9535\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.2697 - loss: 1.8765 - val_accuracy: 0.2326 - val_loss: 1.9264\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3724 - loss: 1.8046 - val_accuracy: 0.3023 - val_loss: 1.8962\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.4355 - loss: 1.7114 - val_accuracy: 0.2093 - val_loss: 1.8105\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.4132 - loss: 1.5948 - val_accuracy: 0.3023 - val_loss: 1.7441\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.4616 - loss: 1.4610 - val_accuracy: 0.3023 - val_loss: 1.6282\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.5632 - loss: 1.2536 - val_accuracy: 0.3721 - val_loss: 1.4654\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.6279 - loss: 1.0133 - val_accuracy: 0.3953 - val_loss: 1.4355\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.3953 - loss: 1.4355\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 39.53%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - accuracy: 0.1207 - loss: 2.4730 - val_accuracy: 0.1395 - val_loss: 2.0889\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1906 - loss: 2.1487 - val_accuracy: 0.1628 - val_loss: 1.9576\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.2045 - loss: 1.9265 - val_accuracy: 0.1628 - val_loss: 1.9695\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2263 - loss: 1.9291 - val_accuracy: 0.2326 - val_loss: 1.9384\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.1955 - loss: 1.8904 - val_accuracy: 0.1628 - val_loss: 1.9241\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.3132 - loss: 1.7592 - val_accuracy: 0.1860 - val_loss: 1.8810\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.3442 - loss: 1.7182 - val_accuracy: 0.3023 - val_loss: 1.8105\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.3994 - loss: 1.5869 - val_accuracy: 0.2558 - val_loss: 1.7409\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - accuracy: 0.3936 - loss: 1.4613 - val_accuracy: 0.2326 - val_loss: 1.6446\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.5859 - loss: 1.3117 - val_accuracy: 0.3721 - val_loss: 1.5243\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3721 - loss: 1.5243\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 37.21%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - accuracy: 0.1186 - loss: 2.1365 - val_accuracy: 0.1395 - val_loss: 1.9406\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2599 - loss: 1.9365 - val_accuracy: 0.1628 - val_loss: 1.9334\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.2152 - loss: 1.8544 - val_accuracy: 0.1628 - val_loss: 1.9692\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2533 - loss: 1.8556 - val_accuracy: 0.1860 - val_loss: 1.9278\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.3014 - loss: 1.7494 - val_accuracy: 0.2791 - val_loss: 1.9049\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.4356 - loss: 1.6747 - val_accuracy: 0.2093 - val_loss: 1.8655\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3663 - loss: 1.5946 - val_accuracy: 0.2326 - val_loss: 1.8331\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4135 - loss: 1.5082 - val_accuracy: 0.3721 - val_loss: 1.7073\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5096 - loss: 1.4055 - val_accuracy: 0.3953 - val_loss: 1.6584\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.5029 - loss: 1.3911 - val_accuracy: 0.4186 - val_loss: 1.5762\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.4186 - loss: 1.5762\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 41.86%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 70ms/step - accuracy: 0.0947 - loss: 2.2470 - val_accuracy: 0.1860 - val_loss: 2.0179\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1265 - loss: 2.0868 - val_accuracy: 0.1628 - val_loss: 1.9982\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2079 - loss: 1.9658 - val_accuracy: 0.0930 - val_loss: 1.9666\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2011 - loss: 1.9448 - val_accuracy: 0.2791 - val_loss: 1.9295\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2701 - loss: 1.8922 - val_accuracy: 0.2093 - val_loss: 1.9507\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2067 - loss: 1.8789 - val_accuracy: 0.2791 - val_loss: 1.9068\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3638 - loss: 1.7759 - val_accuracy: 0.2326 - val_loss: 1.8908\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3341 - loss: 1.7380 - val_accuracy: 0.2791 - val_loss: 1.8353\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2924 - loss: 1.6616 - val_accuracy: 0.2791 - val_loss: 1.8015\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4229 - loss: 1.5526 - val_accuracy: 0.3023 - val_loss: 1.7032\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3023 - loss: 1.7032\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 71ms/step - accuracy: 0.1786 - loss: 2.4599 - val_accuracy: 0.0930 - val_loss: 2.1232\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1985 - loss: 2.1525 - val_accuracy: 0.1860 - val_loss: 2.0192\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2087 - loss: 1.9266 - val_accuracy: 0.1163 - val_loss: 2.1704\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.1775 - loss: 1.9351 - val_accuracy: 0.2326 - val_loss: 1.8925\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2864 - loss: 1.8327 - val_accuracy: 0.3256 - val_loss: 1.8780\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4319 - loss: 1.6729 - val_accuracy: 0.3023 - val_loss: 1.8153\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4462 - loss: 1.5339 - val_accuracy: 0.3721 - val_loss: 1.7069\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.5573 - loss: 1.3677 - val_accuracy: 0.3953 - val_loss: 1.5950\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.6336 - loss: 1.1840 - val_accuracy: 0.4186 - val_loss: 1.5210\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.6106 - loss: 1.1147 - val_accuracy: 0.5814 - val_loss: 1.3411\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.5814 - loss: 1.3411\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 58.14%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 53ms/step - accuracy: 0.1377 - loss: 2.6166 - val_accuracy: 0.1163 - val_loss: 2.1818\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.1354 - loss: 2.2745 - val_accuracy: 0.1395 - val_loss: 1.9449\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2221 - loss: 2.0520 - val_accuracy: 0.2093 - val_loss: 1.9410\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.1227 - loss: 1.9805 - val_accuracy: 0.1163 - val_loss: 1.9358\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.2011 - loss: 1.9155 - val_accuracy: 0.2326 - val_loss: 1.9059\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.2221 - loss: 1.8519 - val_accuracy: 0.2093 - val_loss: 1.8806\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.2557 - loss: 1.7812 - val_accuracy: 0.2326 - val_loss: 1.8665\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.4062 - loss: 1.6852 - val_accuracy: 0.3256 - val_loss: 1.7969\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3790 - loss: 1.6663 - val_accuracy: 0.2791 - val_loss: 1.7623\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.4635 - loss: 1.5158 - val_accuracy: 0.3256 - val_loss: 1.6694\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3256 - loss: 1.6694\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - accuracy: 0.1470 - loss: 2.0407 - val_accuracy: 0.1860 - val_loss: 1.9511\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1209 - loss: 1.9946 - val_accuracy: 0.1163 - val_loss: 1.9699\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.1326 - loss: 1.9174 - val_accuracy: 0.2093 - val_loss: 1.9572\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3117 - loss: 1.8586 - val_accuracy: 0.1860 - val_loss: 1.9060\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3615 - loss: 1.7725 - val_accuracy: 0.2093 - val_loss: 1.8880\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3797 - loss: 1.6515 - val_accuracy: 0.2093 - val_loss: 1.8448\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4039 - loss: 1.5780 - val_accuracy: 0.3256 - val_loss: 1.7171\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4739 - loss: 1.4296 - val_accuracy: 0.3721 - val_loss: 1.6814\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5829 - loss: 1.2102 - val_accuracy: 0.4186 - val_loss: 1.4778\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.6503 - loss: 1.1279 - val_accuracy: 0.3488 - val_loss: 1.5574\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3488 - loss: 1.5574\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 34.88%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - accuracy: 0.1952 - loss: 2.3761 - val_accuracy: 0.1395 - val_loss: 2.0442\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1724 - loss: 2.1349 - val_accuracy: 0.1163 - val_loss: 1.9701\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2303 - loss: 1.8914 - val_accuracy: 0.1395 - val_loss: 1.9535\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1839 - loss: 1.9548 - val_accuracy: 0.2326 - val_loss: 1.9325\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2076 - loss: 1.8945 - val_accuracy: 0.2558 - val_loss: 1.9185\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2758 - loss: 1.8425 - val_accuracy: 0.2093 - val_loss: 1.9155\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2972 - loss: 1.8335 - val_accuracy: 0.3256 - val_loss: 1.8540\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3858 - loss: 1.7062 - val_accuracy: 0.2558 - val_loss: 1.8633\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4845 - loss: 1.5772 - val_accuracy: 0.3256 - val_loss: 1.7666\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4679 - loss: 1.5006 - val_accuracy: 0.3256 - val_loss: 1.7037\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3256 - loss: 1.7037\n",
      "Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - accuracy: 0.1932 - loss: 2.0053 - val_accuracy: 0.1628 - val_loss: 1.9638\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2176 - loss: 1.9148 - val_accuracy: 0.1395 - val_loss: 1.9492\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2340 - loss: 1.9215 - val_accuracy: 0.1395 - val_loss: 1.9865\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2662 - loss: 1.8846 - val_accuracy: 0.1860 - val_loss: 1.9488\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2956 - loss: 1.8566 - val_accuracy: 0.2326 - val_loss: 1.9126\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3017 - loss: 1.8434 - val_accuracy: 0.2791 - val_loss: 1.8687\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3969 - loss: 1.7513 - val_accuracy: 0.2093 - val_loss: 1.8610\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3645 - loss: 1.6967 - val_accuracy: 0.2093 - val_loss: 1.9328\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3834 - loss: 1.6043 - val_accuracy: 0.2558 - val_loss: 1.7934\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4390 - loss: 1.5119 - val_accuracy: 0.2558 - val_loss: 1.8252\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2558 - loss: 1.8252\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - accuracy: 0.1804 - loss: 2.0043 - val_accuracy: 0.1395 - val_loss: 1.9568\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1249 - loss: 1.9423 - val_accuracy: 0.0930 - val_loss: 1.9479\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1865 - loss: 1.9433 - val_accuracy: 0.1628 - val_loss: 1.9518\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2925 - loss: 1.8943 - val_accuracy: 0.1395 - val_loss: 1.9445\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2931 - loss: 1.8530 - val_accuracy: 0.1860 - val_loss: 1.9317\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2965 - loss: 1.8017 - val_accuracy: 0.2093 - val_loss: 1.9433\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2694 - loss: 1.8123 - val_accuracy: 0.2326 - val_loss: 1.9121\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2770 - loss: 1.7466 - val_accuracy: 0.3488 - val_loss: 1.8138\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3768 - loss: 1.5965 - val_accuracy: 0.2791 - val_loss: 1.8441\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3641 - loss: 1.5988 - val_accuracy: 0.3023 - val_loss: 1.7982\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3023 - loss: 1.7982\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - accuracy: 0.1170 - loss: 2.0470 - val_accuracy: 0.1163 - val_loss: 1.9723\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1840 - loss: 1.9322 - val_accuracy: 0.3488 - val_loss: 1.9312\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2136 - loss: 1.9292 - val_accuracy: 0.1163 - val_loss: 1.9281\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3144 - loss: 1.8960 - val_accuracy: 0.2558 - val_loss: 1.9343\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.3146 - loss: 1.8400 - val_accuracy: 0.3023 - val_loss: 1.9196\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3553 - loss: 1.7453 - val_accuracy: 0.2326 - val_loss: 1.9498\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3568 - loss: 1.6902 - val_accuracy: 0.3488 - val_loss: 1.8982\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4036 - loss: 1.6058 - val_accuracy: 0.2791 - val_loss: 1.8767\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5094 - loss: 1.5068 - val_accuracy: 0.3256 - val_loss: 1.8457\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.4912 - loss: 1.4561 - val_accuracy: 0.3023 - val_loss: 1.8271\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3023 - loss: 1.8271\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - accuracy: 0.1596 - loss: 2.0484 - val_accuracy: 0.0930 - val_loss: 1.9438\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.1952 - loss: 1.9590 - val_accuracy: 0.1628 - val_loss: 1.9494\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2471 - loss: 1.9361 - val_accuracy: 0.1628 - val_loss: 1.9459\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3147 - loss: 1.8924 - val_accuracy: 0.2093 - val_loss: 1.9543\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2871 - loss: 1.8603 - val_accuracy: 0.2326 - val_loss: 1.9261\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2987 - loss: 1.8178 - val_accuracy: 0.2093 - val_loss: 1.9346\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3576 - loss: 1.7373 - val_accuracy: 0.2093 - val_loss: 1.8706\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4193 - loss: 1.5726 - val_accuracy: 0.3488 - val_loss: 1.8200\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.4212 - loss: 1.5375 - val_accuracy: 0.2558 - val_loss: 1.8029\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3748 - loss: 1.5663 - val_accuracy: 0.2791 - val_loss: 1.8207\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.2791 - loss: 1.8207\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - accuracy: 0.1124 - loss: 1.9735 - val_accuracy: 0.2093 - val_loss: 1.9371\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2224 - loss: 1.9348 - val_accuracy: 0.2326 - val_loss: 1.9343\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2559 - loss: 1.9105 - val_accuracy: 0.1860 - val_loss: 1.9398\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2642 - loss: 1.8723 - val_accuracy: 0.1860 - val_loss: 1.9251\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.3108 - loss: 1.8219 - val_accuracy: 0.2326 - val_loss: 1.9283\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2972 - loss: 1.7501 - val_accuracy: 0.3023 - val_loss: 1.8794\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3842 - loss: 1.6870 - val_accuracy: 0.2558 - val_loss: 1.9035\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.3830 - loss: 1.6176 - val_accuracy: 0.3721 - val_loss: 1.7811\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.4979 - loss: 1.5130 - val_accuracy: 0.3721 - val_loss: 1.7333\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5013 - loss: 1.4951 - val_accuracy: 0.3488 - val_loss: 1.7679\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3488 - loss: 1.7679\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 34.88%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - accuracy: 0.0876 - loss: 1.9897 - val_accuracy: 0.1163 - val_loss: 1.9511\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.2081 - loss: 1.8985 - val_accuracy: 0.1395 - val_loss: 1.9609\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1815 - loss: 1.9401 - val_accuracy: 0.1628 - val_loss: 1.9534\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2342 - loss: 1.9153 - val_accuracy: 0.2093 - val_loss: 1.9490\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2824 - loss: 1.8714 - val_accuracy: 0.2558 - val_loss: 1.9524\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2723 - loss: 1.8513 - val_accuracy: 0.2558 - val_loss: 1.9340\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2711 - loss: 1.8169 - val_accuracy: 0.2326 - val_loss: 1.9277\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.3103 - loss: 1.7785 - val_accuracy: 0.3023 - val_loss: 1.8956\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3267 - loss: 1.7389 - val_accuracy: 0.2791 - val_loss: 1.8693\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4052 - loss: 1.6402 - val_accuracy: 0.2326 - val_loss: 1.9230\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2326 - loss: 1.9230\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 60ms/step - accuracy: 0.1508 - loss: 1.9832 - val_accuracy: 0.2326 - val_loss: 1.9457\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.2114 - loss: 1.9344 - val_accuracy: 0.1628 - val_loss: 1.9456\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.2181 - loss: 1.9302 - val_accuracy: 0.1628 - val_loss: 1.9471\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.3081 - loss: 1.9014 - val_accuracy: 0.1860 - val_loss: 1.9489\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.3329 - loss: 1.8352 - val_accuracy: 0.2558 - val_loss: 1.9231\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2900 - loss: 1.7830 - val_accuracy: 0.3023 - val_loss: 1.9274\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.3694 - loss: 1.6670 - val_accuracy: 0.2558 - val_loss: 1.9087\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - accuracy: 0.3979 - loss: 1.6090 - val_accuracy: 0.3023 - val_loss: 1.8284\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.3616 - loss: 1.5842 - val_accuracy: 0.2791 - val_loss: 1.8335\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.4406 - loss: 1.4638 - val_accuracy: 0.2791 - val_loss: 1.7794\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.2791 - loss: 1.7794\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 72ms/step - accuracy: 0.1178 - loss: 2.0264 - val_accuracy: 0.1395 - val_loss: 1.9378\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.1644 - loss: 1.9329 - val_accuracy: 0.0930 - val_loss: 1.9448\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.2037 - loss: 1.9391 - val_accuracy: 0.1628 - val_loss: 1.9559\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step - accuracy: 0.1314 - loss: 1.9431 - val_accuracy: 0.1628 - val_loss: 1.9478\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.2489 - loss: 1.9175 - val_accuracy: 0.2093 - val_loss: 1.9380\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.2777 - loss: 1.8738 - val_accuracy: 0.2326 - val_loss: 1.9163\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.2674 - loss: 1.8223 - val_accuracy: 0.2326 - val_loss: 1.9098\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.3197 - loss: 1.7802 - val_accuracy: 0.2093 - val_loss: 1.8760\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.3670 - loss: 1.7256 - val_accuracy: 0.2558 - val_loss: 1.8471\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.3541 - loss: 1.6308 - val_accuracy: 0.3256 - val_loss: 1.8037\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.3256 - loss: 1.8037\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 65ms/step - accuracy: 0.1685 - loss: 2.0285 - val_accuracy: 0.2093 - val_loss: 1.9443\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - accuracy: 0.1728 - loss: 1.9295 - val_accuracy: 0.0930 - val_loss: 1.9385\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.2194 - loss: 1.9039 - val_accuracy: 0.1860 - val_loss: 1.9217\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 79ms/step - accuracy: 0.2763 - loss: 1.8659 - val_accuracy: 0.1860 - val_loss: 1.9004\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - accuracy: 0.3311 - loss: 1.7681 - val_accuracy: 0.2558 - val_loss: 1.8975\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - accuracy: 0.3778 - loss: 1.6168 - val_accuracy: 0.2093 - val_loss: 1.8763\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step - accuracy: 0.4506 - loss: 1.4825 - val_accuracy: 0.3256 - val_loss: 1.7543\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step - accuracy: 0.4468 - loss: 1.4222 - val_accuracy: 0.2791 - val_loss: 1.7371\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.5165 - loss: 1.3421 - val_accuracy: 0.3721 - val_loss: 1.5906\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.5996 - loss: 1.1607 - val_accuracy: 0.4186 - val_loss: 1.5316\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.4186 - loss: 1.5316\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 41.86%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 66ms/step - accuracy: 0.2153 - loss: 1.9865 - val_accuracy: 0.1628 - val_loss: 1.9422\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - accuracy: 0.1809 - loss: 1.9397 - val_accuracy: 0.2326 - val_loss: 1.9407\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.2350 - loss: 1.9359 - val_accuracy: 0.1395 - val_loss: 1.9456\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.3212 - loss: 1.9099 - val_accuracy: 0.1860 - val_loss: 1.9574\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - accuracy: 0.3166 - loss: 1.8510 - val_accuracy: 0.2558 - val_loss: 1.9147\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - accuracy: 0.3574 - loss: 1.8159 - val_accuracy: 0.2326 - val_loss: 1.8817\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - accuracy: 0.3243 - loss: 1.7799 - val_accuracy: 0.2558 - val_loss: 1.8744\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step - accuracy: 0.3911 - loss: 1.6571 - val_accuracy: 0.2791 - val_loss: 1.8429\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - accuracy: 0.3463 - loss: 1.5869 - val_accuracy: 0.2791 - val_loss: 1.8093\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.4166 - loss: 1.6067 - val_accuracy: 0.3256 - val_loss: 1.8305\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.3256 - loss: 1.8305\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 62ms/step - accuracy: 0.1303 - loss: 2.0218 - val_accuracy: 0.1860 - val_loss: 1.9462\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.1425 - loss: 1.9415 - val_accuracy: 0.1628 - val_loss: 1.9472\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - accuracy: 0.2539 - loss: 1.9385 - val_accuracy: 0.0930 - val_loss: 1.9548\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.2824 - loss: 1.9192 - val_accuracy: 0.1628 - val_loss: 1.9613\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.3221 - loss: 1.8837 - val_accuracy: 0.1163 - val_loss: 1.9484\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.3080 - loss: 1.8388 - val_accuracy: 0.2326 - val_loss: 1.9515\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.3100 - loss: 1.8154 - val_accuracy: 0.2558 - val_loss: 1.9599\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.2960 - loss: 1.6846 - val_accuracy: 0.2558 - val_loss: 1.9275\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - accuracy: 0.3401 - loss: 1.6151 - val_accuracy: 0.2326 - val_loss: 1.8141\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - accuracy: 0.3968 - loss: 1.5182 - val_accuracy: 0.3953 - val_loss: 1.7500\n",
      "2/2 - 0s - 13ms/step - accuracy: 0.3953 - loss: 1.7500\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 39.53%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 59ms/step - accuracy: 0.1545 - loss: 2.0000 - val_accuracy: 0.1395 - val_loss: 1.9678\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.1009 - loss: 1.9574 - val_accuracy: 0.1163 - val_loss: 1.9488\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.2056 - loss: 1.9357 - val_accuracy: 0.1860 - val_loss: 1.9522\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2411 - loss: 1.9251 - val_accuracy: 0.1395 - val_loss: 1.9627\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.3048 - loss: 1.8854 - val_accuracy: 0.2326 - val_loss: 1.9508\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.3100 - loss: 1.8483 - val_accuracy: 0.2093 - val_loss: 1.9333\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - accuracy: 0.3285 - loss: 1.8027 - val_accuracy: 0.1628 - val_loss: 1.9398\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.2863 - loss: 1.7364 - val_accuracy: 0.2791 - val_loss: 1.9179\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.3275 - loss: 1.7010 - val_accuracy: 0.2791 - val_loss: 1.9019\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.3355 - loss: 1.6645 - val_accuracy: 0.2791 - val_loss: 1.8659\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.2791 - loss: 1.8659\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - accuracy: 0.0799 - loss: 2.0828 - val_accuracy: 0.0930 - val_loss: 1.9765\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.1685 - loss: 1.9308 - val_accuracy: 0.2326 - val_loss: 1.9440\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3056 - loss: 1.9242 - val_accuracy: 0.1163 - val_loss: 1.9348\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2335 - loss: 1.9026 - val_accuracy: 0.2093 - val_loss: 1.9261\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3005 - loss: 1.8559 - val_accuracy: 0.2558 - val_loss: 1.9578\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.2751 - loss: 1.8139 - val_accuracy: 0.2791 - val_loss: 1.8725\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3547 - loss: 1.6958 - val_accuracy: 0.3488 - val_loss: 1.8235\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4340 - loss: 1.5681 - val_accuracy: 0.3721 - val_loss: 1.7493\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4887 - loss: 1.4985 - val_accuracy: 0.3488 - val_loss: 1.7411\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.5308 - loss: 1.3613 - val_accuracy: 0.3953 - val_loss: 1.7064\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3953 - loss: 1.7064\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 39.53%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - accuracy: 0.1317 - loss: 1.9877 - val_accuracy: 0.1395 - val_loss: 1.9669\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.1730 - loss: 1.9407 - val_accuracy: 0.1860 - val_loss: 1.9402\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.1784 - loss: 1.9340 - val_accuracy: 0.2093 - val_loss: 1.9355\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.2512 - loss: 1.9171 - val_accuracy: 0.1860 - val_loss: 1.9397\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3051 - loss: 1.8888 - val_accuracy: 0.2558 - val_loss: 1.9090\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3118 - loss: 1.8608 - val_accuracy: 0.2791 - val_loss: 1.8867\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3425 - loss: 1.7745 - val_accuracy: 0.2558 - val_loss: 1.8631\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3951 - loss: 1.6565 - val_accuracy: 0.2791 - val_loss: 1.8287\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4115 - loss: 1.6849 - val_accuracy: 0.3721 - val_loss: 1.7339\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4166 - loss: 1.6046 - val_accuracy: 0.3488 - val_loss: 1.7293\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3488 - loss: 1.7293\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 34.88%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - accuracy: 0.1430 - loss: 1.9809 - val_accuracy: 0.0930 - val_loss: 2.0129\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1855 - loss: 1.9340 - val_accuracy: 0.1395 - val_loss: 1.9675\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2088 - loss: 1.8985 - val_accuracy: 0.1860 - val_loss: 1.9337\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3057 - loss: 1.8393 - val_accuracy: 0.2093 - val_loss: 1.9044\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3860 - loss: 1.7314 - val_accuracy: 0.2791 - val_loss: 1.8741\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3593 - loss: 1.6627 - val_accuracy: 0.2093 - val_loss: 1.8896\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3825 - loss: 1.5523 - val_accuracy: 0.3488 - val_loss: 1.7142\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.4782 - loss: 1.3739 - val_accuracy: 0.2791 - val_loss: 1.7409\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.5310 - loss: 1.3043 - val_accuracy: 0.3488 - val_loss: 1.6473\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.6491 - loss: 1.0283 - val_accuracy: 0.4186 - val_loss: 1.5264\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.4186 - loss: 1.5264\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 41.86%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - accuracy: 0.1541 - loss: 2.4568 - val_accuracy: 0.1395 - val_loss: 1.9924\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1963 - loss: 1.9684 - val_accuracy: 0.0930 - val_loss: 1.9517\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1739 - loss: 1.9298 - val_accuracy: 0.1163 - val_loss: 1.9502\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2426 - loss: 1.9261 - val_accuracy: 0.1860 - val_loss: 1.9516\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2467 - loss: 1.9142 - val_accuracy: 0.1860 - val_loss: 1.9468\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.2797 - loss: 1.8685 - val_accuracy: 0.2326 - val_loss: 1.9419\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3085 - loss: 1.8393 - val_accuracy: 0.2326 - val_loss: 1.9264\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3188 - loss: 1.8095 - val_accuracy: 0.2326 - val_loss: 1.9375\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3244 - loss: 1.7308 - val_accuracy: 0.2326 - val_loss: 1.9083\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3132 - loss: 1.6889 - val_accuracy: 0.2558 - val_loss: 1.8280\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.2558 - loss: 1.8280\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - accuracy: 0.1839 - loss: 2.0640 - val_accuracy: 0.2558 - val_loss: 1.9624\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1693 - loss: 1.9252 - val_accuracy: 0.1628 - val_loss: 1.9558\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2004 - loss: 1.9414 - val_accuracy: 0.1860 - val_loss: 1.9463\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2795 - loss: 1.9046 - val_accuracy: 0.2093 - val_loss: 1.9347\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3121 - loss: 1.8653 - val_accuracy: 0.1628 - val_loss: 1.9385\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3083 - loss: 1.8128 - val_accuracy: 0.2558 - val_loss: 1.9026\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3191 - loss: 1.7309 - val_accuracy: 0.2558 - val_loss: 1.8997\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3387 - loss: 1.6561 - val_accuracy: 0.1628 - val_loss: 1.8761\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3615 - loss: 1.5928 - val_accuracy: 0.2791 - val_loss: 1.8556\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4579 - loss: 1.3953 - val_accuracy: 0.3023 - val_loss: 1.7268\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.3023 - loss: 1.7268\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - accuracy: 0.1454 - loss: 2.1027 - val_accuracy: 0.0930 - val_loss: 1.9662\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1547 - loss: 1.9540 - val_accuracy: 0.1628 - val_loss: 1.9440\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2568 - loss: 1.9301 - val_accuracy: 0.1628 - val_loss: 1.9425\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2569 - loss: 1.9148 - val_accuracy: 0.1860 - val_loss: 1.9568\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2305 - loss: 1.9107 - val_accuracy: 0.1860 - val_loss: 1.9587\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3157 - loss: 1.8240 - val_accuracy: 0.2326 - val_loss: 1.9467\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3170 - loss: 1.7739 - val_accuracy: 0.2326 - val_loss: 1.9047\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4250 - loss: 1.6996 - val_accuracy: 0.2791 - val_loss: 1.8613\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3401 - loss: 1.6900 - val_accuracy: 0.2093 - val_loss: 1.8440\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3503 - loss: 1.6604 - val_accuracy: 0.3023 - val_loss: 1.7742\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3023 - loss: 1.7742\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1064 - loss: 1.9672 - val_accuracy: 0.0930 - val_loss: 1.9670\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.1570 - loss: 1.9385 - val_accuracy: 0.0930 - val_loss: 1.9546\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.1892 - loss: 1.9318 - val_accuracy: 0.2326 - val_loss: 1.9514\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.2764 - loss: 1.9083 - val_accuracy: 0.1860 - val_loss: 1.9651\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2302 - loss: 1.9032 - val_accuracy: 0.2326 - val_loss: 1.9490\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.3247 - loss: 1.8407 - val_accuracy: 0.1628 - val_loss: 1.9760\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2843 - loss: 1.7686 - val_accuracy: 0.2791 - val_loss: 1.8794\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.3163 - loss: 1.7272 - val_accuracy: 0.2558 - val_loss: 1.8748\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.3730 - loss: 1.6815 - val_accuracy: 0.3488 - val_loss: 1.8032\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.3948 - loss: 1.6483 - val_accuracy: 0.2326 - val_loss: 1.8212\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2326 - loss: 1.8212\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - accuracy: 0.1634 - loss: 1.9685 - val_accuracy: 0.1395 - val_loss: 1.9424\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1833 - loss: 1.9444 - val_accuracy: 0.2093 - val_loss: 1.9431\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2442 - loss: 1.9310 - val_accuracy: 0.1860 - val_loss: 1.9432\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.2006 - loss: 1.9238 - val_accuracy: 0.2093 - val_loss: 1.9409\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2738 - loss: 1.9121 - val_accuracy: 0.2791 - val_loss: 1.9307\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2806 - loss: 1.8893 - val_accuracy: 0.2326 - val_loss: 1.8919\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.3084 - loss: 1.8189 - val_accuracy: 0.2326 - val_loss: 1.9002\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2981 - loss: 1.7878 - val_accuracy: 0.1860 - val_loss: 1.8998\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.3109 - loss: 1.6475 - val_accuracy: 0.3023 - val_loss: 1.8209\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.4153 - loss: 1.6085 - val_accuracy: 0.2093 - val_loss: 1.7929\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.2093 - loss: 1.7929\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - accuracy: 0.1368 - loss: 1.9705 - val_accuracy: 0.1860 - val_loss: 1.9566\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2419 - loss: 1.9355 - val_accuracy: 0.1163 - val_loss: 1.9493\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2308 - loss: 1.9336 - val_accuracy: 0.1628 - val_loss: 1.9478\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2759 - loss: 1.9008 - val_accuracy: 0.1628 - val_loss: 1.9490\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.3207 - loss: 1.8162 - val_accuracy: 0.2558 - val_loss: 1.9167\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3159 - loss: 1.7876 - val_accuracy: 0.2791 - val_loss: 1.8830\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.3539 - loss: 1.7024 - val_accuracy: 0.3488 - val_loss: 1.9090\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.3552 - loss: 1.5922 - val_accuracy: 0.2093 - val_loss: 1.9482\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4232 - loss: 1.5012 - val_accuracy: 0.2558 - val_loss: 1.8032\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.4132 - loss: 1.4626 - val_accuracy: 0.2791 - val_loss: 1.8374\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2791 - loss: 1.8374\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - accuracy: 0.1843 - loss: 1.9736 - val_accuracy: 0.1395 - val_loss: 1.9437\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1392 - loss: 1.9518 - val_accuracy: 0.1860 - val_loss: 1.9414\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1279 - loss: 1.9376 - val_accuracy: 0.1860 - val_loss: 1.9370\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.1589 - loss: 1.9330 - val_accuracy: 0.1395 - val_loss: 1.9449\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2780 - loss: 1.9074 - val_accuracy: 0.2558 - val_loss: 1.9455\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2566 - loss: 1.8781 - val_accuracy: 0.1860 - val_loss: 1.9596\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2631 - loss: 1.8348 - val_accuracy: 0.2326 - val_loss: 1.9325\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2669 - loss: 1.7628 - val_accuracy: 0.2326 - val_loss: 1.8890\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3071 - loss: 1.7416 - val_accuracy: 0.2326 - val_loss: 1.8549\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.3821 - loss: 1.6543 - val_accuracy: 0.2326 - val_loss: 1.7940\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2326 - loss: 1.7940\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - accuracy: 0.1799 - loss: 1.9608 - val_accuracy: 0.1628 - val_loss: 1.9445\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1412 - loss: 1.9437 - val_accuracy: 0.1395 - val_loss: 1.9492\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1845 - loss: 1.9355 - val_accuracy: 0.1395 - val_loss: 1.9473\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2176 - loss: 1.9182 - val_accuracy: 0.1628 - val_loss: 1.9455\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2493 - loss: 1.8732 - val_accuracy: 0.1860 - val_loss: 1.9365\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2862 - loss: 1.8171 - val_accuracy: 0.2791 - val_loss: 1.9005\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2586 - loss: 1.7571 - val_accuracy: 0.3023 - val_loss: 1.8352\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.3695 - loss: 1.6309 - val_accuracy: 0.1628 - val_loss: 1.7973\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.4272 - loss: 1.5597 - val_accuracy: 0.3488 - val_loss: 1.6687\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.4589 - loss: 1.4317 - val_accuracy: 0.3256 - val_loss: 1.6720\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.3256 - loss: 1.6720\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1372 - loss: 1.9659 - val_accuracy: 0.1628 - val_loss: 1.9343\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1621 - loss: 1.9589 - val_accuracy: 0.0930 - val_loss: 1.9568\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1667 - loss: 1.9372 - val_accuracy: 0.1395 - val_loss: 1.9553\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2211 - loss: 1.9342 - val_accuracy: 0.2326 - val_loss: 1.9548\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2126 - loss: 1.9140 - val_accuracy: 0.1860 - val_loss: 1.9683\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2522 - loss: 1.9077 - val_accuracy: 0.2093 - val_loss: 1.9428\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2282 - loss: 1.8714 - val_accuracy: 0.1628 - val_loss: 1.9300\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2836 - loss: 1.7958 - val_accuracy: 0.2558 - val_loss: 1.8906\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.3869 - loss: 1.7206 - val_accuracy: 0.2791 - val_loss: 1.8680\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.3365 - loss: 1.6645 - val_accuracy: 0.3488 - val_loss: 1.8410\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3488 - loss: 1.8410\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 34.88%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - accuracy: 0.1216 - loss: 1.9609 - val_accuracy: 0.0930 - val_loss: 1.9675\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1280 - loss: 1.9483 - val_accuracy: 0.1628 - val_loss: 1.9453\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1650 - loss: 1.9384 - val_accuracy: 0.1628 - val_loss: 1.9482\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2472 - loss: 1.9118 - val_accuracy: 0.2326 - val_loss: 1.9627\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2552 - loss: 1.8802 - val_accuracy: 0.1860 - val_loss: 1.9538\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3447 - loss: 1.7888 - val_accuracy: 0.1628 - val_loss: 2.0078\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.3533 - loss: 1.7052 - val_accuracy: 0.1860 - val_loss: 1.8987\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.3744 - loss: 1.6596 - val_accuracy: 0.2326 - val_loss: 1.8365\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.4122 - loss: 1.4854 - val_accuracy: 0.2791 - val_loss: 1.8238\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.4318 - loss: 1.4559 - val_accuracy: 0.3256 - val_loss: 1.6624\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.3256 - loss: 1.6624\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 53ms/step - accuracy: 0.1659 - loss: 1.9889 - val_accuracy: 0.1860 - val_loss: 1.9535\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1188 - loss: 1.9524 - val_accuracy: 0.0930 - val_loss: 1.9473\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.2362 - loss: 1.9433 - val_accuracy: 0.1395 - val_loss: 1.9473\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.2393 - loss: 1.9370 - val_accuracy: 0.1628 - val_loss: 1.9492\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2469 - loss: 1.9207 - val_accuracy: 0.1860 - val_loss: 1.9455\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2620 - loss: 1.8961 - val_accuracy: 0.1860 - val_loss: 1.9363\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2895 - loss: 1.8639 - val_accuracy: 0.2326 - val_loss: 1.9067\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3281 - loss: 1.7698 - val_accuracy: 0.1860 - val_loss: 1.9269\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.3741 - loss: 1.6612 - val_accuracy: 0.3023 - val_loss: 1.8580\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - accuracy: 0.2894 - loss: 1.6907 - val_accuracy: 0.2558 - val_loss: 1.8058\n",
      "2/2 - 0s - 14ms/step - accuracy: 0.2558 - loss: 1.8058\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 67ms/step - accuracy: 0.1028 - loss: 1.9784 - val_accuracy: 0.1860 - val_loss: 1.9524\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1564 - loss: 1.9397 - val_accuracy: 0.1395 - val_loss: 1.9512\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.2470 - loss: 1.9289 - val_accuracy: 0.1628 - val_loss: 1.9688\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2906 - loss: 1.8879 - val_accuracy: 0.1395 - val_loss: 1.9385\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.2770 - loss: 1.8499 - val_accuracy: 0.1628 - val_loss: 1.9191\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.3291 - loss: 1.6965 - val_accuracy: 0.3023 - val_loss: 1.8584\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.3580 - loss: 1.6495 - val_accuracy: 0.2791 - val_loss: 1.7881\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.4245 - loss: 1.5174 - val_accuracy: 0.3721 - val_loss: 1.6475\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.5314 - loss: 1.3503 - val_accuracy: 0.3256 - val_loss: 1.5900\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.5782 - loss: 1.1546 - val_accuracy: 0.4884 - val_loss: 1.4271\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.4884 - loss: 1.4271\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 48.84%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 65ms/step - accuracy: 0.1838 - loss: 1.9897 - val_accuracy: 0.1860 - val_loss: 1.9588\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.1759 - loss: 1.9411 - val_accuracy: 0.1395 - val_loss: 1.9521\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.2207 - loss: 1.9275 - val_accuracy: 0.1395 - val_loss: 1.9782\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.2288 - loss: 1.9117 - val_accuracy: 0.1395 - val_loss: 1.9804\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.2426 - loss: 1.9306 - val_accuracy: 0.1628 - val_loss: 1.9397\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - accuracy: 0.2857 - loss: 1.8595 - val_accuracy: 0.2558 - val_loss: 1.9256\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.3087 - loss: 1.7785 - val_accuracy: 0.2558 - val_loss: 1.8808\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.3375 - loss: 1.7601 - val_accuracy: 0.2093 - val_loss: 1.8770\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2884 - loss: 1.7104 - val_accuracy: 0.3023 - val_loss: 1.8362\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.3855 - loss: 1.5203 - val_accuracy: 0.2326 - val_loss: 1.7874\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.2326 - loss: 1.7874\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 62ms/step - accuracy: 0.1276 - loss: 1.9675 - val_accuracy: 0.0930 - val_loss: 1.9576\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.1318 - loss: 1.9533 - val_accuracy: 0.0930 - val_loss: 1.9478\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1491 - loss: 1.9436 - val_accuracy: 0.1395 - val_loss: 1.9497\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.3064 - loss: 1.9349 - val_accuracy: 0.1628 - val_loss: 1.9506\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2479 - loss: 1.9153 - val_accuracy: 0.1628 - val_loss: 1.9551\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2921 - loss: 1.8754 - val_accuracy: 0.1628 - val_loss: 1.9612\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.3074 - loss: 1.8056 - val_accuracy: 0.1860 - val_loss: 1.9257\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.3016 - loss: 1.7170 - val_accuracy: 0.2093 - val_loss: 1.8906\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.4120 - loss: 1.5737 - val_accuracy: 0.3488 - val_loss: 1.7605\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.4481 - loss: 1.4287 - val_accuracy: 0.2093 - val_loss: 1.8536\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.2093 - loss: 1.8536\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 53ms/step - accuracy: 0.1592 - loss: 1.9607 - val_accuracy: 0.1163 - val_loss: 1.9530\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.1580 - loss: 1.9466 - val_accuracy: 0.1860 - val_loss: 1.9471\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1271 - loss: 1.9389 - val_accuracy: 0.1395 - val_loss: 1.9579\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2014 - loss: 1.9348 - val_accuracy: 0.1395 - val_loss: 1.9732\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1842 - loss: 1.9224 - val_accuracy: 0.0930 - val_loss: 1.9732\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2329 - loss: 1.9047 - val_accuracy: 0.1628 - val_loss: 1.9492\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2518 - loss: 1.8701 - val_accuracy: 0.2326 - val_loss: 1.9455\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3051 - loss: 1.7852 - val_accuracy: 0.2558 - val_loss: 1.9023\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.4257 - loss: 1.6668 - val_accuracy: 0.2558 - val_loss: 1.8919\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.3161 - loss: 1.7072 - val_accuracy: 0.2558 - val_loss: 1.8156\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.2558 - loss: 1.8156\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - accuracy: 0.1717 - loss: 1.9743 - val_accuracy: 0.1163 - val_loss: 1.9776\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1828 - loss: 1.9312 - val_accuracy: 0.1395 - val_loss: 1.9534\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1515 - loss: 1.9390 - val_accuracy: 0.0930 - val_loss: 1.9510\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1802 - loss: 1.9339 - val_accuracy: 0.1628 - val_loss: 1.9407\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.2552 - loss: 1.9135 - val_accuracy: 0.2093 - val_loss: 1.9926\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2387 - loss: 1.8594 - val_accuracy: 0.2093 - val_loss: 1.9509\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2954 - loss: 1.8241 - val_accuracy: 0.1860 - val_loss: 1.9957\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3568 - loss: 1.7563 - val_accuracy: 0.3953 - val_loss: 1.8712\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3146 - loss: 1.7031 - val_accuracy: 0.1628 - val_loss: 1.8556\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3660 - loss: 1.6097 - val_accuracy: 0.2326 - val_loss: 1.8926\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.2326 - loss: 1.8926\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - accuracy: 0.1298 - loss: 1.9752 - val_accuracy: 0.2093 - val_loss: 1.9434\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1313 - loss: 1.9778 - val_accuracy: 0.0930 - val_loss: 1.9539\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1644 - loss: 1.9374 - val_accuracy: 0.0930 - val_loss: 1.9542\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2196 - loss: 1.9200 - val_accuracy: 0.2326 - val_loss: 1.9605\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2317 - loss: 1.9079 - val_accuracy: 0.2558 - val_loss: 1.9392\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2964 - loss: 1.8738 - val_accuracy: 0.2558 - val_loss: 1.9195\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.3151 - loss: 1.8345 - val_accuracy: 0.3256 - val_loss: 1.8683\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2734 - loss: 1.7536 - val_accuracy: 0.2791 - val_loss: 1.8142\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3154 - loss: 1.6647 - val_accuracy: 0.3256 - val_loss: 1.9544\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3202 - loss: 1.6079 - val_accuracy: 0.3256 - val_loss: 1.7497\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3256 - loss: 1.7497\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - accuracy: 0.1788 - loss: 2.1082 - val_accuracy: 0.1395 - val_loss: 1.9489\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1577 - loss: 1.9483 - val_accuracy: 0.1395 - val_loss: 1.9470\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1976 - loss: 1.9470 - val_accuracy: 0.1395 - val_loss: 1.9453\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.2239 - loss: 1.9336 - val_accuracy: 0.2093 - val_loss: 1.9430\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2870 - loss: 1.9137 - val_accuracy: 0.1860 - val_loss: 1.9413\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2440 - loss: 1.8828 - val_accuracy: 0.2558 - val_loss: 1.9532\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2063 - loss: 1.8396 - val_accuracy: 0.2791 - val_loss: 1.9322\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2941 - loss: 1.7544 - val_accuracy: 0.2093 - val_loss: 1.9765\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3612 - loss: 1.6484 - val_accuracy: 0.2791 - val_loss: 1.8756\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3973 - loss: 1.5834 - val_accuracy: 0.3023 - val_loss: 1.8493\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3023 - loss: 1.8493\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 30.23%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - accuracy: 0.1733 - loss: 2.3707 - val_accuracy: 0.0930 - val_loss: 1.9785\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1856 - loss: 1.9696 - val_accuracy: 0.1860 - val_loss: 1.9499\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1763 - loss: 1.9645 - val_accuracy: 0.0930 - val_loss: 1.9460\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.2427 - loss: 1.9368 - val_accuracy: 0.2093 - val_loss: 1.9442\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.3151 - loss: 1.9303 - val_accuracy: 0.2093 - val_loss: 1.9433\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2924 - loss: 1.9162 - val_accuracy: 0.1395 - val_loss: 1.9509\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2110 - loss: 1.8861 - val_accuracy: 0.2093 - val_loss: 1.9674\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3094 - loss: 1.8228 - val_accuracy: 0.2093 - val_loss: 1.9639\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3195 - loss: 1.7866 - val_accuracy: 0.2326 - val_loss: 1.9260\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3116 - loss: 1.6893 - val_accuracy: 0.2326 - val_loss: 1.9360\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.2326 - loss: 1.9360\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - accuracy: 0.1034 - loss: 1.9753 - val_accuracy: 0.0930 - val_loss: 1.9464\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1908 - loss: 1.9433 - val_accuracy: 0.1163 - val_loss: 1.9620\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2589 - loss: 1.9187 - val_accuracy: 0.2326 - val_loss: 1.9541\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2940 - loss: 1.8695 - val_accuracy: 0.1628 - val_loss: 1.9724\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3063 - loss: 1.8230 - val_accuracy: 0.2093 - val_loss: 1.9324\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4103 - loss: 1.7184 - val_accuracy: 0.2791 - val_loss: 1.8876\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.4001 - loss: 1.6516 - val_accuracy: 0.3023 - val_loss: 1.8221\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4268 - loss: 1.5679 - val_accuracy: 0.3023 - val_loss: 1.7838\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5829 - loss: 1.3740 - val_accuracy: 0.3488 - val_loss: 1.6334\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.4544 - loss: 1.3602 - val_accuracy: 0.3953 - val_loss: 1.6462\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3953 - loss: 1.6462\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 39.53%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - accuracy: 0.1157 - loss: 2.0056 - val_accuracy: 0.0930 - val_loss: 1.9489\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1784 - loss: 1.9440 - val_accuracy: 0.0930 - val_loss: 1.9468\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1849 - loss: 1.9403 - val_accuracy: 0.1163 - val_loss: 1.9470\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2547 - loss: 1.9294 - val_accuracy: 0.1395 - val_loss: 1.9489\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.1927 - loss: 1.9216 - val_accuracy: 0.1628 - val_loss: 1.9367\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2574 - loss: 1.8594 - val_accuracy: 0.1628 - val_loss: 1.9220\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2905 - loss: 1.8400 - val_accuracy: 0.1628 - val_loss: 1.9321\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3038 - loss: 1.7705 - val_accuracy: 0.2093 - val_loss: 1.8509\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.3115 - loss: 1.7070 - val_accuracy: 0.3256 - val_loss: 1.8066\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.3795 - loss: 1.5657 - val_accuracy: 0.3256 - val_loss: 1.7290\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.3256 - loss: 1.7290\n",
      "Configuration: {'conv_layers': 2, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 32.56%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - accuracy: 0.1670 - loss: 1.9588 - val_accuracy: 0.1163 - val_loss: 1.9996\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1480 - loss: 1.9202 - val_accuracy: 0.1163 - val_loss: 1.9687\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2178 - loss: 1.9304 - val_accuracy: 0.0930 - val_loss: 1.9781\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2547 - loss: 1.9176 - val_accuracy: 0.1163 - val_loss: 1.9734\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2213 - loss: 1.9262 - val_accuracy: 0.0930 - val_loss: 1.9587\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2222 - loss: 1.9268 - val_accuracy: 0.0930 - val_loss: 1.9569\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2236 - loss: 1.9070 - val_accuracy: 0.1395 - val_loss: 1.9728\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2922 - loss: 1.8726 - val_accuracy: 0.1860 - val_loss: 1.9731\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.3236 - loss: 1.8645 - val_accuracy: 0.1628 - val_loss: 1.9581\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.3149 - loss: 1.8417 - val_accuracy: 0.1628 - val_loss: 1.9286\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.1628 - loss: 1.9286\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - accuracy: 0.1135 - loss: 1.9596 - val_accuracy: 0.1395 - val_loss: 1.9658\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1138 - loss: 1.9511 - val_accuracy: 0.1860 - val_loss: 1.9693\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1746 - loss: 1.9360 - val_accuracy: 0.1395 - val_loss: 1.9643\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2143 - loss: 1.9348 - val_accuracy: 0.1395 - val_loss: 1.9655\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2289 - loss: 1.9359 - val_accuracy: 0.1395 - val_loss: 1.9732\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1749 - loss: 1.9315 - val_accuracy: 0.1628 - val_loss: 1.9781\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1485 - loss: 1.9384 - val_accuracy: 0.1163 - val_loss: 1.9717\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2604 - loss: 1.9234 - val_accuracy: 0.1163 - val_loss: 1.9769\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2563 - loss: 1.9040 - val_accuracy: 0.1628 - val_loss: 1.9586\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2277 - loss: 1.9167 - val_accuracy: 0.1395 - val_loss: 1.9406\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1395 - loss: 1.9406\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 13.95%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - accuracy: 0.1096 - loss: 1.9672 - val_accuracy: 0.1395 - val_loss: 1.9549\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1363 - loss: 1.9457 - val_accuracy: 0.0930 - val_loss: 1.9677\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1719 - loss: 1.9386 - val_accuracy: 0.1628 - val_loss: 1.9612\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1811 - loss: 1.9384 - val_accuracy: 0.0930 - val_loss: 1.9703\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2070 - loss: 1.9246 - val_accuracy: 0.2093 - val_loss: 1.9759\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1983 - loss: 1.9234 - val_accuracy: 0.2093 - val_loss: 1.9716\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2729 - loss: 1.8992 - val_accuracy: 0.0930 - val_loss: 2.0103\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2212 - loss: 1.8901 - val_accuracy: 0.1628 - val_loss: 1.9481\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.3243 - loss: 1.8577 - val_accuracy: 0.1860 - val_loss: 1.9284\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.3191 - loss: 1.8202 - val_accuracy: 0.2326 - val_loss: 1.9189\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2326 - loss: 1.9189\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - accuracy: 0.1230 - loss: 1.9641 - val_accuracy: 0.1860 - val_loss: 1.9573\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1336 - loss: 1.9398 - val_accuracy: 0.1163 - val_loss: 1.9671\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1152 - loss: 1.9511 - val_accuracy: 0.0930 - val_loss: 1.9643\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2130 - loss: 1.9392 - val_accuracy: 0.0930 - val_loss: 1.9615\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1832 - loss: 1.9356 - val_accuracy: 0.1163 - val_loss: 1.9609\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2652 - loss: 1.9251 - val_accuracy: 0.1395 - val_loss: 1.9700\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.3094 - loss: 1.9098 - val_accuracy: 0.1628 - val_loss: 1.9824\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2205 - loss: 1.8971 - val_accuracy: 0.1628 - val_loss: 1.9790\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.3063 - loss: 1.8888 - val_accuracy: 0.1395 - val_loss: 1.9777\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2935 - loss: 1.8493 - val_accuracy: 0.2093 - val_loss: 1.9536\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2093 - loss: 1.9536\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - accuracy: 0.1262 - loss: 1.9670 - val_accuracy: 0.2093 - val_loss: 1.9594\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1379 - loss: 1.9524 - val_accuracy: 0.0930 - val_loss: 1.9602\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1829 - loss: 1.9393 - val_accuracy: 0.0930 - val_loss: 1.9552\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2067 - loss: 1.9332 - val_accuracy: 0.0930 - val_loss: 1.9643\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.1942 - loss: 1.9262 - val_accuracy: 0.1163 - val_loss: 1.9654\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2273 - loss: 1.9197 - val_accuracy: 0.1860 - val_loss: 1.9540\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2020 - loss: 1.9130 - val_accuracy: 0.1860 - val_loss: 1.9495\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2729 - loss: 1.9149 - val_accuracy: 0.1860 - val_loss: 1.9366\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.3283 - loss: 1.8831 - val_accuracy: 0.1860 - val_loss: 1.9347\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2790 - loss: 1.8680 - val_accuracy: 0.1860 - val_loss: 1.9117\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.1860 - loss: 1.9117\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 18.60%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - accuracy: 0.1071 - loss: 1.9926 - val_accuracy: 0.1163 - val_loss: 1.9658\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2079 - loss: 1.9321 - val_accuracy: 0.1163 - val_loss: 1.9642\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2068 - loss: 1.9369 - val_accuracy: 0.0930 - val_loss: 1.9814\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1583 - loss: 1.9501 - val_accuracy: 0.0930 - val_loss: 1.9732\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1686 - loss: 1.9300 - val_accuracy: 0.1628 - val_loss: 1.9699\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1445 - loss: 1.9302 - val_accuracy: 0.1163 - val_loss: 1.9719\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2246 - loss: 1.9234 - val_accuracy: 0.1860 - val_loss: 1.9802\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2571 - loss: 1.9000 - val_accuracy: 0.1395 - val_loss: 1.9876\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.1766 - loss: 1.9157 - val_accuracy: 0.1628 - val_loss: 1.9778\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2645 - loss: 1.9148 - val_accuracy: 0.1628 - val_loss: 1.9607\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.1628 - loss: 1.9607\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 57ms/step - accuracy: 0.1477 - loss: 1.9590 - val_accuracy: 0.0930 - val_loss: 1.9563\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1440 - loss: 1.9409 - val_accuracy: 0.0930 - val_loss: 1.9530\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1593 - loss: 1.9397 - val_accuracy: 0.0930 - val_loss: 1.9633\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1514 - loss: 1.9381 - val_accuracy: 0.0930 - val_loss: 1.9640\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1751 - loss: 1.9464 - val_accuracy: 0.1395 - val_loss: 1.9720\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.1839 - loss: 1.9227 - val_accuracy: 0.1628 - val_loss: 1.9884\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.1900 - loss: 1.9271 - val_accuracy: 0.1395 - val_loss: 1.9618\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2932 - loss: 1.8672 - val_accuracy: 0.1628 - val_loss: 2.0038\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2792 - loss: 1.8206 - val_accuracy: 0.2093 - val_loss: 1.9686\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.3256 - loss: 1.7795 - val_accuracy: 0.1628 - val_loss: 2.1058\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.1628 - loss: 2.1058\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 54ms/step - accuracy: 0.0885 - loss: 1.9593 - val_accuracy: 0.2326 - val_loss: 1.9360\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1459 - loss: 1.9542 - val_accuracy: 0.0930 - val_loss: 1.9553\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1328 - loss: 1.9449 - val_accuracy: 0.0930 - val_loss: 1.9544\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1486 - loss: 1.9512 - val_accuracy: 0.0930 - val_loss: 1.9549\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1942 - loss: 1.9340 - val_accuracy: 0.0930 - val_loss: 1.9584\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1581 - loss: 1.9353 - val_accuracy: 0.1395 - val_loss: 1.9616\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2212 - loss: 1.9230 - val_accuracy: 0.1395 - val_loss: 1.9949\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1619 - loss: 1.9396 - val_accuracy: 0.1628 - val_loss: 1.9753\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.2113 - loss: 1.9141 - val_accuracy: 0.1860 - val_loss: 1.9634\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2691 - loss: 1.8964 - val_accuracy: 0.0930 - val_loss: 1.9748\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.0930 - loss: 1.9748\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 9.30%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 54ms/step - accuracy: 0.1172 - loss: 1.9576 - val_accuracy: 0.1628 - val_loss: 1.9514\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.2040 - loss: 1.9495 - val_accuracy: 0.0698 - val_loss: 1.9536\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1406 - loss: 1.9445 - val_accuracy: 0.0930 - val_loss: 1.9557\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.1615 - loss: 1.9408 - val_accuracy: 0.0930 - val_loss: 1.9597\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1527 - loss: 1.9375 - val_accuracy: 0.0930 - val_loss: 1.9524\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.1774 - loss: 1.9261 - val_accuracy: 0.1628 - val_loss: 1.9440\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2125 - loss: 1.9176 - val_accuracy: 0.1628 - val_loss: 1.9357\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.2808 - loss: 1.8792 - val_accuracy: 0.1860 - val_loss: 1.9496\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - accuracy: 0.3586 - loss: 1.8295 - val_accuracy: 0.2093 - val_loss: 1.9519\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - accuracy: 0.2708 - loss: 1.7960 - val_accuracy: 0.2326 - val_loss: 1.9341\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.2326 - loss: 1.9341\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 23.26%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 67ms/step - accuracy: 0.1450 - loss: 1.9685 - val_accuracy: 0.0930 - val_loss: 1.9593\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1831 - loss: 1.9384 - val_accuracy: 0.1163 - val_loss: 1.9491\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.1739 - loss: 1.9452 - val_accuracy: 0.1628 - val_loss: 1.9494\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1817 - loss: 1.9389 - val_accuracy: 0.0930 - val_loss: 1.9534\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.1203 - loss: 1.9440 - val_accuracy: 0.1163 - val_loss: 1.9518\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.1724 - loss: 1.9315 - val_accuracy: 0.1628 - val_loss: 1.9562\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2001 - loss: 1.9253 - val_accuracy: 0.1628 - val_loss: 1.9645\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2017 - loss: 1.9185 - val_accuracy: 0.2093 - val_loss: 1.9675\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.2399 - loss: 1.8840 - val_accuracy: 0.1860 - val_loss: 1.9495\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.2714 - loss: 1.8610 - val_accuracy: 0.1860 - val_loss: 1.9498\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.1860 - loss: 1.9498\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 18.60%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 65ms/step - accuracy: 0.1262 - loss: 1.9683 - val_accuracy: 0.1163 - val_loss: 1.9646\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1318 - loss: 1.9455 - val_accuracy: 0.1395 - val_loss: 1.9553\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.1255 - loss: 1.9425 - val_accuracy: 0.1628 - val_loss: 1.9504\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.1661 - loss: 1.9317 - val_accuracy: 0.0930 - val_loss: 1.9695\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1764 - loss: 1.9412 - val_accuracy: 0.2093 - val_loss: 1.9647\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2154 - loss: 1.9282 - val_accuracy: 0.2093 - val_loss: 1.9527\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - accuracy: 0.2074 - loss: 1.9175 - val_accuracy: 0.1860 - val_loss: 1.9664\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.2541 - loss: 1.8961 - val_accuracy: 0.1163 - val_loss: 1.9641\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.2555 - loss: 1.8512 - val_accuracy: 0.1860 - val_loss: 1.9638\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.3409 - loss: 1.7931 - val_accuracy: 0.2093 - val_loss: 1.8759\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.2093 - loss: 1.8759\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - accuracy: 0.1377 - loss: 1.9584 - val_accuracy: 0.1163 - val_loss: 1.9701\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1199 - loss: 1.9598 - val_accuracy: 0.1163 - val_loss: 1.9587\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1238 - loss: 1.9477 - val_accuracy: 0.1163 - val_loss: 1.9548\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.1755 - loss: 1.9394 - val_accuracy: 0.1163 - val_loss: 1.9556\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1277 - loss: 1.9410 - val_accuracy: 0.1628 - val_loss: 1.9551\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1845 - loss: 1.9381 - val_accuracy: 0.1395 - val_loss: 1.9565\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1891 - loss: 1.9403 - val_accuracy: 0.0930 - val_loss: 1.9570\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.1738 - loss: 1.9418 - val_accuracy: 0.1163 - val_loss: 1.9559\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1534 - loss: 1.9347 - val_accuracy: 0.1395 - val_loss: 1.9624\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1777 - loss: 1.9418 - val_accuracy: 0.1628 - val_loss: 1.9565\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.1628 - loss: 1.9565\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - accuracy: 0.1314 - loss: 1.9454 - val_accuracy: 0.0930 - val_loss: 1.9763\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1037 - loss: 1.9632 - val_accuracy: 0.0930 - val_loss: 1.9626\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1766 - loss: 1.9455 - val_accuracy: 0.0930 - val_loss: 1.9596\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1538 - loss: 1.9399 - val_accuracy: 0.1395 - val_loss: 1.9530\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2270 - loss: 1.9365 - val_accuracy: 0.1395 - val_loss: 1.9538\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2769 - loss: 1.9080 - val_accuracy: 0.1628 - val_loss: 1.9538\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2573 - loss: 1.8882 - val_accuracy: 0.2558 - val_loss: 1.9405\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.2826 - loss: 1.8625 - val_accuracy: 0.2093 - val_loss: 1.9100\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2940 - loss: 1.8025 - val_accuracy: 0.2326 - val_loss: 1.8849\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2814 - loss: 1.7452 - val_accuracy: 0.2093 - val_loss: 1.8938\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.2093 - loss: 1.8938\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - accuracy: 0.0944 - loss: 1.9643 - val_accuracy: 0.1395 - val_loss: 1.9389\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1400 - loss: 1.9483 - val_accuracy: 0.1628 - val_loss: 1.9440\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2125 - loss: 1.9398 - val_accuracy: 0.1628 - val_loss: 1.9481\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1532 - loss: 1.9362 - val_accuracy: 0.1395 - val_loss: 1.9582\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1815 - loss: 1.9347 - val_accuracy: 0.1395 - val_loss: 1.9656\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1887 - loss: 1.9397 - val_accuracy: 0.1163 - val_loss: 1.9630\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2199 - loss: 1.9173 - val_accuracy: 0.1628 - val_loss: 1.9966\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1477 - loss: 1.9411 - val_accuracy: 0.1628 - val_loss: 1.9758\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.2330 - loss: 1.9253 - val_accuracy: 0.1628 - val_loss: 1.9516\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2531 - loss: 1.9107 - val_accuracy: 0.1628 - val_loss: 1.9513\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1628 - loss: 1.9513\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - accuracy: 0.1209 - loss: 1.9640 - val_accuracy: 0.0930 - val_loss: 1.9465\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1631 - loss: 1.9494 - val_accuracy: 0.1395 - val_loss: 1.9606\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1671 - loss: 1.9390 - val_accuracy: 0.0930 - val_loss: 1.9652\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2087 - loss: 1.9265 - val_accuracy: 0.0930 - val_loss: 1.9742\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2240 - loss: 1.9388 - val_accuracy: 0.1860 - val_loss: 1.9584\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2737 - loss: 1.9049 - val_accuracy: 0.1163 - val_loss: 1.9653\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2952 - loss: 1.8843 - val_accuracy: 0.2326 - val_loss: 1.9617\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3281 - loss: 1.8477 - val_accuracy: 0.1628 - val_loss: 1.9473\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.3088 - loss: 1.7996 - val_accuracy: 0.2791 - val_loss: 1.9070\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3175 - loss: 1.7085 - val_accuracy: 0.2558 - val_loss: 1.9268\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.2558 - loss: 1.9268\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - accuracy: 0.1853 - loss: 1.9587 - val_accuracy: 0.1163 - val_loss: 1.9633\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1520 - loss: 1.9416 - val_accuracy: 0.2093 - val_loss: 1.9511\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1241 - loss: 1.9423 - val_accuracy: 0.0930 - val_loss: 1.9593\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1313 - loss: 1.9379 - val_accuracy: 0.0930 - val_loss: 1.9694\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1905 - loss: 1.9327 - val_accuracy: 0.0930 - val_loss: 1.9900\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1280 - loss: 1.9352 - val_accuracy: 0.1163 - val_loss: 1.9643\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1704 - loss: 1.9345 - val_accuracy: 0.1163 - val_loss: 1.9590\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1894 - loss: 1.9285 - val_accuracy: 0.1395 - val_loss: 1.9633\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2620 - loss: 1.9143 - val_accuracy: 0.1163 - val_loss: 1.9924\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1686 - loss: 1.9293 - val_accuracy: 0.1628 - val_loss: 1.9577\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1628 - loss: 1.9577\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - accuracy: 0.1060 - loss: 1.9747 - val_accuracy: 0.1163 - val_loss: 1.9572\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1339 - loss: 1.9454 - val_accuracy: 0.1395 - val_loss: 1.9473\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1533 - loss: 1.9487 - val_accuracy: 0.1163 - val_loss: 1.9536\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1766 - loss: 1.9410 - val_accuracy: 0.1395 - val_loss: 1.9678\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.2411 - loss: 1.9391 - val_accuracy: 0.0930 - val_loss: 1.9791\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1815 - loss: 1.9435 - val_accuracy: 0.1395 - val_loss: 1.9667\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1974 - loss: 1.9348 - val_accuracy: 0.1163 - val_loss: 1.9593\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2240 - loss: 1.9283 - val_accuracy: 0.0930 - val_loss: 1.9510\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2669 - loss: 1.9245 - val_accuracy: 0.1628 - val_loss: 1.9562\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.2686 - loss: 1.8957 - val_accuracy: 0.1395 - val_loss: 1.9831\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1395 - loss: 1.9831\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 13.95%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - accuracy: 0.2044 - loss: 1.9577 - val_accuracy: 0.0930 - val_loss: 1.9530\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1593 - loss: 1.9610 - val_accuracy: 0.1163 - val_loss: 1.9577\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1271 - loss: 1.9450 - val_accuracy: 0.1628 - val_loss: 1.9477\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1488 - loss: 1.9412 - val_accuracy: 0.1395 - val_loss: 1.9543\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.1395 - loss: 1.9452 - val_accuracy: 0.0930 - val_loss: 1.9645\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2480 - loss: 1.9142 - val_accuracy: 0.1628 - val_loss: 1.9830\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1977 - loss: 1.9343 - val_accuracy: 0.0698 - val_loss: 1.9808\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2458 - loss: 1.9141 - val_accuracy: 0.1395 - val_loss: 1.9706\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2257 - loss: 1.8921 - val_accuracy: 0.1395 - val_loss: 1.9632\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2295 - loss: 1.8649 - val_accuracy: 0.1395 - val_loss: 1.9778\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1395 - loss: 1.9778\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 1, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 13.95%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - accuracy: 0.1397 - loss: 1.9540 - val_accuracy: 0.0930 - val_loss: 1.9653\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1658 - loss: 1.9406 - val_accuracy: 0.0930 - val_loss: 1.9813\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1935 - loss: 1.9430 - val_accuracy: 0.0930 - val_loss: 1.9776\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.2030 - loss: 1.9307 - val_accuracy: 0.0930 - val_loss: 1.9915\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1801 - loss: 1.9343 - val_accuracy: 0.1860 - val_loss: 1.9632\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2656 - loss: 1.9103 - val_accuracy: 0.2093 - val_loss: 1.9529\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2384 - loss: 1.8953 - val_accuracy: 0.1628 - val_loss: 1.9545\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2650 - loss: 1.8595 - val_accuracy: 0.2093 - val_loss: 1.9632\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2693 - loss: 1.8299 - val_accuracy: 0.1860 - val_loss: 1.9204\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2871 - loss: 1.8257 - val_accuracy: 0.1628 - val_loss: 1.9372\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.1628 - loss: 1.9372\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - accuracy: 0.1588 - loss: 1.9580 - val_accuracy: 0.1395 - val_loss: 1.9506\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1583 - loss: 1.9471 - val_accuracy: 0.0930 - val_loss: 1.9495\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1480 - loss: 1.9398 - val_accuracy: 0.1628 - val_loss: 1.9556\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2092 - loss: 1.9276 - val_accuracy: 0.1395 - val_loss: 1.9688\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1785 - loss: 1.9407 - val_accuracy: 0.1628 - val_loss: 1.9617\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2033 - loss: 1.9283 - val_accuracy: 0.2326 - val_loss: 1.9422\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2238 - loss: 1.9264 - val_accuracy: 0.1395 - val_loss: 1.9590\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2160 - loss: 1.8794 - val_accuracy: 0.1395 - val_loss: 1.9445\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2768 - loss: 1.8609 - val_accuracy: 0.2326 - val_loss: 1.9289\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2736 - loss: 1.8422 - val_accuracy: 0.2093 - val_loss: 1.9247\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2093 - loss: 1.9247\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - accuracy: 0.1087 - loss: 1.9515 - val_accuracy: 0.0930 - val_loss: 1.9492\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1920 - loss: 1.9446 - val_accuracy: 0.1163 - val_loss: 1.9541\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1474 - loss: 1.9454 - val_accuracy: 0.1395 - val_loss: 1.9549\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1642 - loss: 1.9417 - val_accuracy: 0.2093 - val_loss: 1.9558\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2000 - loss: 1.9322 - val_accuracy: 0.1628 - val_loss: 1.9660\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2081 - loss: 1.9216 - val_accuracy: 0.1628 - val_loss: 1.9616\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2256 - loss: 1.9192 - val_accuracy: 0.1628 - val_loss: 1.9460\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2682 - loss: 1.8761 - val_accuracy: 0.2093 - val_loss: 1.9491\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2487 - loss: 1.8366 - val_accuracy: 0.1628 - val_loss: 1.9759\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2410 - loss: 1.7839 - val_accuracy: 0.2093 - val_loss: 1.8789\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2093 - loss: 1.8789\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - accuracy: 0.1522 - loss: 1.9534 - val_accuracy: 0.0930 - val_loss: 1.9629\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1482 - loss: 1.9418 - val_accuracy: 0.0930 - val_loss: 1.9561\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1998 - loss: 1.9391 - val_accuracy: 0.0930 - val_loss: 1.9577\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1278 - loss: 1.9436 - val_accuracy: 0.0930 - val_loss: 1.9617\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1873 - loss: 1.9357 - val_accuracy: 0.0930 - val_loss: 1.9669\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1497 - loss: 1.9474 - val_accuracy: 0.0930 - val_loss: 1.9583\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1841 - loss: 1.9360 - val_accuracy: 0.0930 - val_loss: 1.9660\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.1480 - loss: 1.9297 - val_accuracy: 0.2326 - val_loss: 1.9812\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2523 - loss: 1.9026 - val_accuracy: 0.2326 - val_loss: 1.9643\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1646 - loss: 1.9263 - val_accuracy: 0.1628 - val_loss: 1.9372\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.1628 - loss: 1.9372\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - accuracy: 0.1254 - loss: 1.9561 - val_accuracy: 0.1395 - val_loss: 1.9638\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1858 - loss: 1.9433 - val_accuracy: 0.1395 - val_loss: 1.9825\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1192 - loss: 1.9511 - val_accuracy: 0.1395 - val_loss: 1.9686\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1547 - loss: 1.9441 - val_accuracy: 0.1628 - val_loss: 1.9581\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1596 - loss: 1.9403 - val_accuracy: 0.1628 - val_loss: 1.9597\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1938 - loss: 1.9291 - val_accuracy: 0.1395 - val_loss: 1.9609\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1917 - loss: 1.9227 - val_accuracy: 0.2326 - val_loss: 1.9583\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.3135 - loss: 1.8942 - val_accuracy: 0.1628 - val_loss: 1.9664\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2188 - loss: 1.8909 - val_accuracy: 0.1395 - val_loss: 1.9443\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.2120 - loss: 1.8710 - val_accuracy: 0.2558 - val_loss: 1.9181\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2558 - loss: 1.9181\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 25.58%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - accuracy: 0.1003 - loss: 1.9583 - val_accuracy: 0.1395 - val_loss: 1.9513\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1177 - loss: 1.9603 - val_accuracy: 0.1395 - val_loss: 1.9560\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1779 - loss: 1.9480 - val_accuracy: 0.1395 - val_loss: 1.9561\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1537 - loss: 1.9428 - val_accuracy: 0.1395 - val_loss: 1.9589\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1086 - loss: 1.9506 - val_accuracy: 0.1163 - val_loss: 1.9631\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.1160 - loss: 1.9459 - val_accuracy: 0.1395 - val_loss: 1.9629\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.1643 - loss: 1.9363 - val_accuracy: 0.1628 - val_loss: 1.9693\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2526 - loss: 1.9334 - val_accuracy: 0.1628 - val_loss: 1.9696\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.2190 - loss: 1.9196 - val_accuracy: 0.1860 - val_loss: 1.9708\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2725 - loss: 1.9104 - val_accuracy: 0.2093 - val_loss: 1.9771\n",
      "2/2 - 0s - 7ms/step - accuracy: 0.2093 - loss: 1.9771\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - accuracy: 0.2024 - loss: 1.9551 - val_accuracy: 0.1163 - val_loss: 1.9550\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1041 - loss: 1.9502 - val_accuracy: 0.1628 - val_loss: 1.9467\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.1776 - loss: 1.9451 - val_accuracy: 0.1628 - val_loss: 1.9486\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2164 - loss: 1.9426 - val_accuracy: 0.1395 - val_loss: 1.9497\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1900 - loss: 1.9375 - val_accuracy: 0.1860 - val_loss: 1.9557\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1746 - loss: 1.9333 - val_accuracy: 0.2093 - val_loss: 1.9604\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2793 - loss: 1.9162 - val_accuracy: 0.1395 - val_loss: 1.9671\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.1600 - loss: 1.9214 - val_accuracy: 0.1860 - val_loss: 1.9559\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2027 - loss: 1.8760 - val_accuracy: 0.1628 - val_loss: 1.9900\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.2840 - loss: 1.8424 - val_accuracy: 0.2093 - val_loss: 1.9825\n",
      "2/2 - 0s - 11ms/step - accuracy: 0.2093 - loss: 1.9825\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 20.93%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 60ms/step - accuracy: 0.0711 - loss: 1.9653 - val_accuracy: 0.0930 - val_loss: 1.9493\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1089 - loss: 1.9485 - val_accuracy: 0.1395 - val_loss: 1.9479\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1190 - loss: 1.9466 - val_accuracy: 0.1395 - val_loss: 1.9484\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1644 - loss: 1.9462 - val_accuracy: 0.1163 - val_loss: 1.9511\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.0902 - loss: 1.9460 - val_accuracy: 0.1163 - val_loss: 1.9532\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1863 - loss: 1.9432 - val_accuracy: 0.1395 - val_loss: 1.9584\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.0775 - loss: 1.9486 - val_accuracy: 0.1163 - val_loss: 1.9546\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1987 - loss: 1.9435 - val_accuracy: 0.0930 - val_loss: 1.9546\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1898 - loss: 1.9382 - val_accuracy: 0.1163 - val_loss: 1.9564\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2117 - loss: 1.9375 - val_accuracy: 0.1395 - val_loss: 1.9626\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.1395 - loss: 1.9626\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 13.95%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - accuracy: 0.1092 - loss: 1.9639 - val_accuracy: 0.0930 - val_loss: 1.9506\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1678 - loss: 1.9450 - val_accuracy: 0.1628 - val_loss: 1.9553\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1725 - loss: 1.9464 - val_accuracy: 0.1628 - val_loss: 1.9491\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1802 - loss: 1.9447 - val_accuracy: 0.1163 - val_loss: 1.9492\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.2050 - loss: 1.9419 - val_accuracy: 0.1395 - val_loss: 1.9551\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.2164 - loss: 1.9320 - val_accuracy: 0.1395 - val_loss: 1.9696\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.2734 - loss: 1.9199 - val_accuracy: 0.1628 - val_loss: 1.9550\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2140 - loss: 1.8926 - val_accuracy: 0.2326 - val_loss: 1.9387\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2241 - loss: 1.8370 - val_accuracy: 0.1628 - val_loss: 1.9064\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2951 - loss: 1.7729 - val_accuracy: 0.1628 - val_loss: 1.9228\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.1628 - loss: 1.9228\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 56ms/step - accuracy: 0.1455 - loss: 1.9596 - val_accuracy: 0.0465 - val_loss: 1.9570\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1739 - loss: 1.9377 - val_accuracy: 0.0930 - val_loss: 1.9554\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - accuracy: 0.1561 - loss: 1.9406 - val_accuracy: 0.0930 - val_loss: 1.9620\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.1174 - loss: 1.9554 - val_accuracy: 0.1628 - val_loss: 1.9493\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1729 - loss: 1.9433 - val_accuracy: 0.1163 - val_loss: 1.9498\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1794 - loss: 1.9453 - val_accuracy: 0.1628 - val_loss: 1.9477\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1693 - loss: 1.9450 - val_accuracy: 0.1395 - val_loss: 1.9476\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1997 - loss: 1.9358 - val_accuracy: 0.1628 - val_loss: 1.9523\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.2069 - loss: 1.9271 - val_accuracy: 0.1628 - val_loss: 1.9681\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - accuracy: 0.2153 - loss: 1.9119 - val_accuracy: 0.2791 - val_loss: 1.9555\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.2791 - loss: 1.9555\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 27.91%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 61ms/step - accuracy: 0.1637 - loss: 1.9520 - val_accuracy: 0.1395 - val_loss: 1.9556\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - accuracy: 0.1327 - loss: 1.9487 - val_accuracy: 0.0930 - val_loss: 1.9495\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1471 - loss: 1.9407 - val_accuracy: 0.0930 - val_loss: 1.9637\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1728 - loss: 1.9344 - val_accuracy: 0.1395 - val_loss: 1.9535\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - accuracy: 0.2083 - loss: 1.9318 - val_accuracy: 0.0930 - val_loss: 1.9590\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - accuracy: 0.1746 - loss: 1.9305 - val_accuracy: 0.1395 - val_loss: 1.9543\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2141 - loss: 1.9328 - val_accuracy: 0.1628 - val_loss: 1.9471\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.2560 - loss: 1.9117 - val_accuracy: 0.1395 - val_loss: 1.9768\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.2480 - loss: 1.8823 - val_accuracy: 0.1163 - val_loss: 1.9816\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.2732 - loss: 1.8175 - val_accuracy: 0.1628 - val_loss: 1.9352\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.1628 - loss: 1.9352\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 63ms/step - accuracy: 0.1085 - loss: 1.9573 - val_accuracy: 0.1860 - val_loss: 1.9505\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1018 - loss: 1.9476 - val_accuracy: 0.1395 - val_loss: 1.9540\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step - accuracy: 0.1548 - loss: 1.9461 - val_accuracy: 0.0930 - val_loss: 1.9563\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.2265 - loss: 1.9401 - val_accuracy: 0.0930 - val_loss: 1.9621\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1735 - loss: 1.9492 - val_accuracy: 0.0930 - val_loss: 1.9623\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1645 - loss: 1.9437 - val_accuracy: 0.0930 - val_loss: 1.9684\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - accuracy: 0.1667 - loss: 1.9404 - val_accuracy: 0.0930 - val_loss: 1.9692\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1164 - loss: 1.9493 - val_accuracy: 0.0930 - val_loss: 1.9644\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - accuracy: 0.1684 - loss: 1.9374 - val_accuracy: 0.0930 - val_loss: 1.9681\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - accuracy: 0.1906 - loss: 1.9298 - val_accuracy: 0.0930 - val_loss: 1.9757\n",
      "2/2 - 0s - 12ms/step - accuracy: 0.0930 - loss: 1.9757\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 9.30%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - accuracy: 0.1559 - loss: 1.9488 - val_accuracy: 0.2093 - val_loss: 1.9508\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2007 - loss: 1.9419 - val_accuracy: 0.1860 - val_loss: 1.9702\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1638 - loss: 1.9400 - val_accuracy: 0.1860 - val_loss: 1.9667\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1267 - loss: 1.9422 - val_accuracy: 0.0930 - val_loss: 1.9579\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2076 - loss: 1.9215 - val_accuracy: 0.1628 - val_loss: 1.9657\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1784 - loss: 1.9353 - val_accuracy: 0.2326 - val_loss: 1.9665\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1422 - loss: 1.9335 - val_accuracy: 0.0930 - val_loss: 1.9664\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2110 - loss: 1.9282 - val_accuracy: 0.1860 - val_loss: 1.9528\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2466 - loss: 1.9085 - val_accuracy: 0.1395 - val_loss: 1.9574\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2477 - loss: 1.8772 - val_accuracy: 0.1860 - val_loss: 1.9641\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.1860 - loss: 1.9641\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.25}, Test Accuracy: 18.60%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - accuracy: 0.0818 - loss: 1.9718 - val_accuracy: 0.1395 - val_loss: 1.9605\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.1727 - loss: 1.9393 - val_accuracy: 0.0930 - val_loss: 1.9650\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1416 - loss: 1.9338 - val_accuracy: 0.1395 - val_loss: 1.9575\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1321 - loss: 1.9498 - val_accuracy: 0.1395 - val_loss: 1.9515\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1497 - loss: 1.9492 - val_accuracy: 0.1395 - val_loss: 1.9582\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2040 - loss: 1.9515 - val_accuracy: 0.1395 - val_loss: 1.9575\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2100 - loss: 1.9412 - val_accuracy: 0.0930 - val_loss: 1.9586\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1838 - loss: 1.9484 - val_accuracy: 0.1628 - val_loss: 1.9597\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2896 - loss: 1.9269 - val_accuracy: 0.1628 - val_loss: 1.9661\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2162 - loss: 1.9220 - val_accuracy: 0.1395 - val_loss: 1.9595\n",
      "2/2 - 0s - 9ms/step - accuracy: 0.1395 - loss: 1.9595\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128], 'dropout': 0.5}, Test Accuracy: 13.95%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - accuracy: 0.0990 - loss: 1.9542 - val_accuracy: 0.1395 - val_loss: 1.9454\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1161 - loss: 1.9456 - val_accuracy: 0.1163 - val_loss: 1.9501\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1606 - loss: 1.9415 - val_accuracy: 0.0930 - val_loss: 1.9599\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1473 - loss: 1.9410 - val_accuracy: 0.0930 - val_loss: 1.9734\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.1858 - loss: 1.9431 - val_accuracy: 0.1395 - val_loss: 1.9618\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.2850 - loss: 1.9145 - val_accuracy: 0.1395 - val_loss: 1.9731\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.2278 - loss: 1.8875 - val_accuracy: 0.1395 - val_loss: 1.9713\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2779 - loss: 1.8550 - val_accuracy: 0.1628 - val_loss: 1.9330\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.2692 - loss: 1.8246 - val_accuracy: 0.1628 - val_loss: 1.9233\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - accuracy: 0.3140 - loss: 1.7027 - val_accuracy: 0.1628 - val_loss: 1.8656\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1628 - loss: 1.8656\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - accuracy: 0.1513 - loss: 1.9695 - val_accuracy: 0.1163 - val_loss: 1.9593\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1372 - loss: 1.9409 - val_accuracy: 0.0930 - val_loss: 1.9745\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1646 - loss: 1.9573 - val_accuracy: 0.1163 - val_loss: 1.9661\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1412 - loss: 1.9428 - val_accuracy: 0.1395 - val_loss: 1.9667\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2466 - loss: 1.9440 - val_accuracy: 0.1395 - val_loss: 1.9584\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1977 - loss: 1.9388 - val_accuracy: 0.1628 - val_loss: 1.9627\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1738 - loss: 1.9356 - val_accuracy: 0.1860 - val_loss: 1.9569\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.3355 - loss: 1.8975 - val_accuracy: 0.1395 - val_loss: 1.9765\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2280 - loss: 1.8950 - val_accuracy: 0.1628 - val_loss: 1.9551\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2854 - loss: 1.8279 - val_accuracy: 0.1628 - val_loss: 1.9217\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1628 - loss: 1.9217\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 60ms/step - accuracy: 0.1361 - loss: 1.9522 - val_accuracy: 0.0930 - val_loss: 1.9495\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - accuracy: 0.1351 - loss: 1.9500 - val_accuracy: 0.0930 - val_loss: 1.9552\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2029 - loss: 1.9422 - val_accuracy: 0.0930 - val_loss: 1.9604\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.1610 - loss: 1.9451 - val_accuracy: 0.1163 - val_loss: 1.9571\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.1501 - loss: 1.9396 - val_accuracy: 0.1395 - val_loss: 1.9566\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.1811 - loss: 1.9408 - val_accuracy: 0.1628 - val_loss: 1.9511\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.2903 - loss: 1.9276 - val_accuracy: 0.1395 - val_loss: 1.9640\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2392 - loss: 1.9125 - val_accuracy: 0.1628 - val_loss: 1.9859\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.2343 - loss: 1.8914 - val_accuracy: 0.1860 - val_loss: 1.9260\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.2304 - loss: 1.8826 - val_accuracy: 0.1860 - val_loss: 1.9033\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1860 - loss: 1.9033\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.25}, Test Accuracy: 18.60%\n",
      "Epoch 1/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - accuracy: 0.1796 - loss: 1.9544 - val_accuracy: 0.0930 - val_loss: 1.9690\n",
      "Epoch 2/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1849 - loss: 1.9509 - val_accuracy: 0.1395 - val_loss: 1.9539\n",
      "Epoch 3/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1466 - loss: 1.9561 - val_accuracy: 0.1163 - val_loss: 1.9450\n",
      "Epoch 4/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1364 - loss: 1.9437 - val_accuracy: 0.0930 - val_loss: 1.9497\n",
      "Epoch 5/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1664 - loss: 1.9440 - val_accuracy: 0.0930 - val_loss: 1.9538\n",
      "Epoch 6/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.1895 - loss: 1.9390 - val_accuracy: 0.1395 - val_loss: 1.9606\n",
      "Epoch 7/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.1816 - loss: 1.9426 - val_accuracy: 0.0930 - val_loss: 1.9583\n",
      "Epoch 8/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.1823 - loss: 1.9478 - val_accuracy: 0.1628 - val_loss: 1.9488\n",
      "Epoch 9/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.2353 - loss: 1.9396 - val_accuracy: 0.1628 - val_loss: 1.9477\n",
      "Epoch 10/10\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.2791 - loss: 1.9290 - val_accuracy: 0.1628 - val_loss: 1.9588\n",
      "2/2 - 0s - 8ms/step - accuracy: 0.1628 - loss: 1.9588\n",
      "Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
      "Best Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}\n",
      "Best Test Accuracy: 58.14%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            if filename.endswith('.tiff'):\n",
    "                image_file = os.path.join(folder, filename)\n",
    "                img = Image.open(image_file).convert('L')\n",
    "                img = img.resize((64, 64))\n",
    "                img_array = np.array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                label_code = filename.split('.')[1][:2]\n",
    "                labels.append(label_map[label_code])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(shear_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Define the range for configurations\n",
    "num_conv_layers_options = [1, 2, 3]\n",
    "num_dense_layers_options = [1, 2]\n",
    "filters_options = [[32], [64], [32, 64]]\n",
    "dense_units_options = [[128], [256], [128, 256]]\n",
    "dropout_options = [0.25, 0.5]\n",
    "\n",
    "# Generate all possible configurations\n",
    "def generate_all_configurations():\n",
    "    configurations = []\n",
    "    for conv_layers, dense_layers, filters, dense_units, dropout in product(\n",
    "            num_conv_layers_options, num_dense_layers_options, filters_options, dense_units_options, dropout_options):\n",
    "        config = {\n",
    "            'conv_layers': conv_layers,\n",
    "            'dense_layers': dense_layers,\n",
    "            'filters': filters,\n",
    "            'dense_units': dense_units,\n",
    "            'dropout': dropout\n",
    "        }\n",
    "        configurations.append(config)\n",
    "    return configurations\n",
    "\n",
    "configurations = generate_all_configurations()\n",
    "best_configuration = {}\n",
    "best_accuracy = 0\n",
    "\n",
    "# Test each configuration\n",
    "for config in configurations:\n",
    "    try:\n",
    "        model = Sequential([InputLayer(input_shape=(64, 64, 1))])\n",
    "        for i in range(config['conv_layers']):\n",
    "            model.add(Conv2D(config['filters'][i % len(config['filters'])], (3, 3), activation='relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        for j in range(config['dense_layers']):\n",
    "            model.add(Dense(config['dense_units'][j % len(config['dense_units'])], activation='relu'))\n",
    "        model.add(Dropout(config['dropout']))\n",
    "        model.add(Dense(len(np.unique(labels_encoded)), activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_test, y_test), epochs=10, verbose=1)\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "        print(f\"Configuration: {config}, Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "        if test_acc > best_accuracy:\n",
    "            best_accuracy = test_acc\n",
    "            best_configuration = config\n",
    "    except Exception as e:\n",
    "        print(f\"Failed configuration {config}: {e}\")\n",
    "\n",
    "# Output best results\n",
    "print(f\"Best Configuration: {best_configuration}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T23:44:43.457494Z",
     "start_time": "2024-08-08T23:39:30.112893Z"
    }
   },
   "id": "294f894aaa516768"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Configuration: {'conv_layers': 3, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [128, 256], 'dropout': 0.5}, Test Accuracy: 16.28%\n",
    "Best Configuration: {'conv_layers': 1, 'dense_layers': 2, 'filters': [32, 64], 'dense_units': [256], 'dropout': 0.25}\n",
    "Best Test Accuracy: 58.14%, give the model , normally\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77c7ea98cfda8160"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4692d4259e090518"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b770d4739cb390ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "27d58e31aa127f7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2f4b1779cd63a6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from skopt.utils import use_named_args\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\", \"DI\": \"disgust\", \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\", \"SA\": \"sadness\", \"SU\": \"surprise\", \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            image_file = os.path.join(folder, filename)\n",
    "            img = Image.open(image_file).convert('L')\n",
    "            img = img.resize((64, 64))\n",
    "            img_array = np.array(img) / 255.0\n",
    "            images.append(img_array)\n",
    "            labels.append(label_map[filename.split('.')[1][:2]])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)\n",
    "labels = LabelEncoder().fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setup data augmentation\n",
    "datagen = ImageDataGenerator(shear_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Define the range of hyperparameters to optimize\n",
    "dimensions = [\n",
    "    Integer(low=1, high=4, name='num_conv_layers'),  # Slightly expanded range\n",
    "    Integer(low=32, high=256, name='num_filters'),  # Practical range for filters\n",
    "    Integer(low=64, high=512, name='num_dense_nodes'),  # Expanded dense nodes range\n",
    "    Real(low=0.1, high=0.5, name='dropout_rate')  # Adjusted dropout range\n",
    "]\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(num_conv_layers, num_filters, num_dense_nodes, dropout_rate):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(64, 64, 1)),\n",
    "        *[layer for i in range(num_conv_layers) for layer in\n",
    "          [Conv2D(num_filters, (3, 3), activation='relu'), MaxPooling2D((2, 2))]],\n",
    "        Flatten(),\n",
    "        Dense(num_dense_nodes, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(labels[0]), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=3, verbose=1, steps_per_epoch=len(X_train) // 32)\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return -accuracy\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "search_result = gp_minimize(func=fitness, dimensions=dimensions, n_calls=20, x0=[2, 64, 128, 0.25])\n",
    "\n",
    "# Output the best results\n",
    "print(\"Best hyperparameters:\")\n",
    "print(\"Number of Convolution Layers:\", search_result.x[0])\n",
    "print(\"Number of Filters:\", search_result.x[1])\n",
    "print(\"Number of Dense Nodes:\", search_result.x[2])\n",
    "print(\"Dropout Rate:\", search_result.x[3])\n",
    "print(\"Best Accuracy Achieved:\", -search_result.fun)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9f07257be2a2a10"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001B[1m2/5\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - accuracy: 0.1976 - loss: 3.4098 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - accuracy: 0.1427 - loss: 4.1482\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.1875 - loss: 2.7741\n",
      "Epoch 3/3\n",
      "\u001B[1m3/5\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.2334 - loss: 2.0583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:49:46.837021: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.1933 - loss: 2.0800\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 76ms/step - accuracy: 0.1403 - loss: 1.9582\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.9616 \n",
      "Epoch 3/3\n",
      "\u001B[1m2/5\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 74ms/step - accuracy: 0.2031 - loss: 1.9168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:49:48.111109: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step - accuracy: 0.1788 - loss: 1.9421\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - accuracy: 0.1845 - loss: 2.3094\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 961us/step - accuracy: 0.1562 - loss: 1.9668\n",
      "Epoch 3/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.1342 - loss: 1.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:49:49.225081: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 132ms/step - accuracy: 0.1546 - loss: 2.0475\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.0000e+00 - loss: 1.9841 \n",
      "Epoch 3/3\n",
      "\u001B[1m1/5\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 127ms/step - accuracy: 0.1562 - loss: 1.9467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:49:51.269999: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 91ms/step - accuracy: 0.1496 - loss: 1.9428\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 43ms/step - accuracy: 0.1580 - loss: 1.9738\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 885us/step - accuracy: 0.1875 - loss: 1.9713\n",
      "Epoch 3/3\n",
      "\u001B[1m3/5\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.2037 - loss: 1.9390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:49:52.680568: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - accuracy: 0.1888 - loss: 1.9413\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 350ms/step - accuracy: 0.1568 - loss: 1.9555\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.0938 - loss: 2.0601  \n",
      "Epoch 3/3\n",
      "\u001B[1m1/5\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 176ms/step - accuracy: 0.2000 - loss: 1.9677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:49:55.997611: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 419ms/step - accuracy: 0.1317 - loss: 1.9510\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - accuracy: 0.2141 - loss: 2.0658\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 954us/step - accuracy: 0.2188 - loss: 2.0380\n",
      "Epoch 3/3\n",
      "\u001B[1m2/5\u001B[0m \u001B[32m━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - accuracy: 0.1452 - loss: 1.9714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:49:58.735493: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - accuracy: 0.1529 - loss: 1.9647\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 357ms/step - accuracy: 0.1627 - loss: 1.9786\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.0938 - loss: 1.9670  \n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:50:01.957975: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 407ms/step - accuracy: 0.1720 - loss: 1.9467\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - accuracy: 0.1493 - loss: 1.9739\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 915us/step - accuracy: 0.1000 - loss: 1.9193\n",
      "Epoch 3/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.2425 - loss: 1.9217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:50:04.882413: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 335ms/step - accuracy: 0.1287 - loss: 1.9792\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.1250 - loss: 1.9561  \n",
      "Epoch 3/3\n",
      "\u001B[1m1/5\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 172ms/step - accuracy: 0.0000e+00 - loss: 1.9770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:50:07.756881: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 408ms/step - accuracy: 0.1016 - loss: 1.9522\n",
      "Epoch 1/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 53ms/step - accuracy: 0.1025 - loss: 2.9107\n",
      "Epoch 2/3\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.1250 - loss: 2.3693 \n",
      "Epoch 3/3\n",
      "\u001B[1m3/5\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - accuracy: 0.0903 - loss: 2.5630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 02:50:10.550404: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - accuracy: 0.1132 - loss: 2.5102\n",
      "Best hyperparameters:\n",
      "Conv Layers: 1\n",
      "Filters: 40\n",
      "Dense Nodes: 361\n",
      "Dropout Rate: 0.3093032192621926\n",
      "Best Accuracy: 0.25581395626068115\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from skopt.utils import use_named_args\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "def load_images_and_labels(folder):\n",
    "    images, labels = [], []\n",
    "    label_map = {\"AN\": \"anger\", \"DI\": \"disgust\", \"FE\": \"fear\", \"HA\": \"happiness\",\n",
    "                 \"SA\": \"sadness\", \"SU\": \"surprise\", \"NE\": \"neutral\"}\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            img = Image.open(os.path.join(folder, filename)).convert('L')\n",
    "            img_array = np.array(img.resize((64, 64))) / 255.0\n",
    "            images.append(img_array)\n",
    "            labels.append(label_map[filename.split('.')[1][:2]])\n",
    "    return np.array(images).reshape(-1, 64, 64, 1), np.array(labels)\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "labels = to_categorical(LabelEncoder().fit_transform(labels))\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(shear_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "dimensions = [\n",
    "    Integer(low=1, high=4, name='num_conv_layers'),\n",
    "    Integer(low=32, high=256, name='num_filters'),\n",
    "    Integer(low=64, high=512, name='num_dense_nodes'),\n",
    "    Real(low=0.1, high=0.5, name='dropout_rate')\n",
    "]\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(num_conv_layers, num_filters, num_dense_nodes, dropout_rate):\n",
    "    # Initialize the model\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(64, 64, 1))\n",
    "    ])\n",
    "\n",
    "    # Dynamically add convolution and pooling layers\n",
    "    for _ in range(num_conv_layers):\n",
    "        model.add(Conv2D(num_filters, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Add flattening, dense, dropout, and output layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_dense_nodes, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model using a data generator\n",
    "    model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=3, verbose=1,\n",
    "              steps_per_epoch=max(1, len(X_train) // 32))  # Ensure there are enough steps per epoch\n",
    "\n",
    "    # Evaluate the model\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return -accuracy\n",
    "\n",
    "\n",
    "\n",
    "search_result = gp_minimize(fitness, dimensions, n_calls=11, x0=[1, 64, 128, 0.3])\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(\"Conv Layers:\", search_result.x[0])\n",
    "print(\"Filters:\", search_result.x[1])\n",
    "print(\"Dense Nodes:\", search_result.x[2])\n",
    "print(\"Dropout Rate:\", search_result.x[3])\n",
    "print(\"Best Accuracy:\", -search_result.fun)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-09T01:50:11.275551Z",
     "start_time": "2024-08-09T01:49:45.458829Z"
    }
   },
   "id": "7f2801fe84cd45de"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16}, Accuracy: 30.23%\n",
      "Tested Configuration: {'conv_layers': 1, 'filters': (128,), 'dense_layers': 4, 'dense_units': (256, 128, 2048, 1024), 'dropout': 0.1, 'epochs': 11}, Accuracy: 46.51%\n",
      "Tested Configuration: {'conv_layers': 4, 'filters': (512, 64, 256, 128), 'dense_layers': 1, 'dense_units': (2048,), 'dropout': 0.4, 'epochs': 32}, Accuracy: 51.16%\n",
      "Tested Configuration: {'conv_layers': 1, 'filters': (512,), 'dense_layers': 4, 'dense_units': (128, 256, 512, 1024), 'dropout': 0.2, 'epochs': 31}, Accuracy: 76.74%\n",
      "Tested Configuration: {'conv_layers': 2, 'filters': (128, 256), 'dense_layers': 3, 'dense_units': (2048, 1024, 512), 'dropout': 0.1, 'epochs': 40}, Accuracy: 81.40%\n",
      "Tested Configuration: {'conv_layers': 3, 'filters': (128, 32, 64), 'dense_layers': 5, 'dense_units': (2048, 128, 1024, 256, 512), 'dropout': 0.8, 'epochs': 11}, Accuracy: 13.95%\n",
      "Tested Configuration: {'conv_layers': 2, 'filters': (512, 64), 'dense_layers': 2, 'dense_units': (128, 256), 'dropout': 0.4, 'epochs': 35}, Accuracy: 83.72%\n",
      "Tested Configuration: {'conv_layers': 3, 'filters': (512, 32, 64), 'dense_layers': 5, 'dense_units': (2048, 256, 512, 128, 1024), 'dropout': 0.1, 'epochs': 40}, Accuracy: 13.95%\n",
      "Tested Configuration: {'conv_layers': 4, 'filters': (32, 128, 64, 512), 'dense_layers': 3, 'dense_units': (256, 2048, 512), 'dropout': 0.3, 'epochs': 15}, Accuracy: 20.93%\n",
      "Tested Configuration: {'conv_layers': 1, 'filters': (32,), 'dense_layers': 1, 'dense_units': (1024,), 'dropout': 0.1, 'epochs': 27}, Accuracy: 81.40%\n",
      "Best Configuration: {'conv_layers': 2, 'filters': (512, 64), 'dense_layers': 2, 'dense_units': (128, 256), 'dropout': 0.4, 'epochs': 35}\n",
      "Best Accuracy: 83.72%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            image_file = os.path.join(folder, filename)\n",
    "            img = Image.open(image_file).convert('L')\n",
    "            img = img.resize((64, 64))  # Resize to 64x64 for consistency\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(img_array)\n",
    "            label_code = filename.split('.')[1][:2]\n",
    "            labels.append(label_map[label_code])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape for CNN input\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configuration generator function\n",
    "def generate_unique_configuration(history):\n",
    "    max_conv_layers = 10  # Increase the maximum number of convolutional layers\n",
    "    max_dense_layers = 5  # Increase the maximum number of dense layers\n",
    "    max_filters = [32, 64, 128, 256, 512]  # Add higher filter sizes\n",
    "    max_dense_units = [128, 256, 512, 1024, 2048]  # Increase dense layer units\n",
    "    max_dropout = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]  # Increase dropout options\n",
    "    epoch_range = (10, 50)  # Increase the range for epochs\n",
    "\n",
    "    while True:\n",
    "        conv_layers = random.randint(1, min(max_conv_layers, len(max_filters)))\n",
    "        dense_layers = random.randint(1, min(max_dense_layers, len(max_dense_units)))\n",
    "        filters = tuple(random.sample(max_filters, conv_layers))\n",
    "        dense_units = tuple(random.sample(max_dense_units, dense_layers))\n",
    "        dropout = random.choice(max_dropout)\n",
    "        epochs = random.randint(*epoch_range)  # Randomly choose epochs within the range\n",
    "\n",
    "        config = {\n",
    "            'conv_layers': conv_layers,\n",
    "            'filters': filters,\n",
    "            'dense_layers': dense_layers,\n",
    "            'dense_units': dense_units,\n",
    "            'dropout': dropout,\n",
    "            'epochs': epochs  # Include epochs in the configuration\n",
    "        }\n",
    "\n",
    "        config_tuple = tuple(sorted((k, tuple(v) if isinstance(v, list) else v) for k, v in config.items()))\n",
    "\n",
    "        if config_tuple not in history:\n",
    "            history.add(config_tuple)\n",
    "            return config\n",
    "\n",
    "# Generating and evaluating models\n",
    "history = set()\n",
    "best_accuracy = 0\n",
    "best_configuration = None\n",
    "\n",
    "while True:  # Generate and test 10 unique configurations\n",
    "    try:\n",
    "        config = generate_unique_configuration(history)\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(shape=(64, 64, 1)))  # Use 'shape' instead of 'input_shape'\n",
    "        for i in range(config['conv_layers']):\n",
    "            model.add(Conv2D(config['filters'][i], (3, 3), activation='relu'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        for j in range(config['dense_layers']):\n",
    "            model.add(Dense(config['dense_units'][j], activation='relu'))\n",
    "        model.add(Dropout(config['dropout']))\n",
    "        model.add(Dense(len(np.unique(labels_encoded)), activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, epochs=config['epochs'], verbose=0)  # Use the randomly chosen epochs\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Tested Configuration: {config}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(f\"Best Configuration: {best_configuration}\")\n",
    "        print(f\"Best Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_configuration = config\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with configuration {config}: {e}\")\n",
    "\n",
    "print(f\"Best Configuration: {best_configuration}\")\n",
    "print(f\"Best Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-09T02:23:28.059779Z",
     "start_time": "2024-08-09T02:14:07.358266Z"
    }
   },
   "id": "872094fbd6de81f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}, Accuracy: 25.58%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 5, 'filters': (128, 64, 512, 32, 256), 'dense_layers': 2, 'dense_units': (512, 128), 'dropout': 0.7, 'epochs': 45, 'batch_size': 16}, Accuracy: 9.30%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 3, 'filters': (128, 512, 32), 'dense_layers': 3, 'dense_units': (1024, 128, 2048), 'dropout': 0.7, 'epochs': 21, 'batch_size': 32}, Accuracy: 9.30%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 3, 'filters': (256, 64, 512), 'dense_layers': 2, 'dense_units': (2048, 128), 'dropout': 0.7, 'epochs': 47, 'batch_size': 128}, Accuracy: 18.60%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 2, 'filters': (512, 128), 'dense_layers': 3, 'dense_units': (512, 256, 1024), 'dropout': 0.7, 'epochs': 21, 'batch_size': 128}, Accuracy: 20.93%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 4, 'filters': (32, 64, 128, 256), 'dense_layers': 2, 'dense_units': (128, 2048), 'dropout': 0.4, 'epochs': 35, 'batch_size': 64}, Accuracy: 46.51%\n",
      "Current Best Accuracy: 46.51% with Configuration: {'conv_layers': 4, 'filters': (32, 64, 128, 256), 'dense_layers': 2, 'dense_units': (128, 2048), 'dropout': 0.4, 'epochs': 35, 'batch_size': 64}\n",
      "Tested Configuration: {'conv_layers': 1, 'filters': (32,), 'dense_layers': 2, 'dense_units': (1024, 256), 'dropout': 0.5, 'epochs': 22, 'batch_size': 128}, Accuracy: 34.88%\n",
      "Current Best Accuracy: 46.51% with Configuration: {'conv_layers': 4, 'filters': (32, 64, 128, 256), 'dense_layers': 2, 'dense_units': (128, 2048), 'dropout': 0.4, 'epochs': 35, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            image_file = os.path.join(folder, filename)\n",
    "            img = Image.open(image_file).convert('L')\n",
    "            img = img.resize((64, 64))  # Resize to 64x64 for consistency\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(img_array)\n",
    "            label_code = filename.split('.')[1][:2]\n",
    "            labels.append(label_map[label_code])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape for CNN input\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation with shear_range=0.2\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)  # Compute quantities required for featurewise normalization\n",
    "\n",
    "# Configuration generator function\n",
    "def generate_unique_configuration(history):\n",
    "    max_conv_layers = 10  # Increase the maximum number of convolutional layers\n",
    "    max_dense_layers = 5  # Increase the maximum number of dense layers\n",
    "    max_filters = [32, 64, 128, 256, 512]  # Add higher filter sizes\n",
    "    max_dense_units = [128, 256, 512, 1024, 2048]  # Increase dense layer units\n",
    "    max_dropout = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]  # Increase dropout options\n",
    "    epoch_range = (10, 50)  # Increase the range for epochs\n",
    "    batch_size_options = [16, 32, 64, 128]  # Possible batch sizes\n",
    "\n",
    "    while True:\n",
    "        conv_layers = random.randint(1, min(max_conv_layers, len(max_filters)))\n",
    "        dense_layers = random.randint(1, min(max_dense_layers, len(max_dense_units)))\n",
    "        filters = tuple(random.sample(max_filters, conv_layers))\n",
    "        dense_units = tuple(random.sample(max_dense_units, dense_layers))\n",
    "        dropout = random.choice(max_dropout)\n",
    "        epochs = random.randint(*epoch_range)  # Randomly choose epochs within the range\n",
    "        batch_size = random.choice(batch_size_options)  # Randomly select a batch size\n",
    "\n",
    "        config = {\n",
    "            'conv_layers': conv_layers,\n",
    "            'filters': filters,\n",
    "            'dense_layers': dense_layers,\n",
    "            'dense_units': dense_units,\n",
    "            'dropout': dropout,\n",
    "            'epochs': epochs,  # Include epochs in the configuration\n",
    "            'batch_size': batch_size  # Include batch size in the configuration\n",
    "        }\n",
    "\n",
    "        config_tuple = tuple(sorted((k, tuple(v) if isinstance(v, list) else v) for k, v in config.items()))\n",
    "\n",
    "        if config_tuple not in history:\n",
    "            history.add(config_tuple)\n",
    "            return config\n",
    "\n",
    "# Function to calculate the output size after Conv2D and MaxPooling\n",
    "def calculate_output_size(input_size, kernel_size, stride=1, padding='valid'):\n",
    "    if padding == 'same':\n",
    "        return input_size\n",
    "    return (input_size - kernel_size) // stride + 1\n",
    "\n",
    "# Generating and evaluating models\n",
    "history = set()\n",
    "best_accuracy = 0\n",
    "best_configuration = None\n",
    "\n",
    "for _ in range(10):  # Generate and test 10 unique configurations\n",
    "    try:\n",
    "        config = generate_unique_configuration(history)\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(shape=(64, 64, 1)))  # Use 'shape' instead of 'input_shape'\n",
    "        input_size = 64  # Starting input size\n",
    "\n",
    "        for i in range(config['conv_layers']):\n",
    "            if calculate_output_size(input_size, 3) < 1:\n",
    "                raise ValueError(f\"Configuration {config} leads to an invalid layer size.\")\n",
    "\n",
    "            model.add(Conv2D(config['filters'][i], (3, 3), activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            input_size = calculate_output_size(input_size, 2, stride=2)\n",
    "\n",
    "        model.add(Flatten())\n",
    "        for j in range(config['dense_layers']):\n",
    "            model.add(Dense(config['dense_units'][j], activation='relu'))\n",
    "        model.add(Dropout(config['dropout']))\n",
    "        model.add(Dense(len(np.unique(labels_encoded)), activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Fit model using data augmentation with dynamic batch size\n",
    "        model.fit(datagen.flow(X_train, y_train, batch_size=config['batch_size']), epochs=config['epochs'], verbose=0)\n",
    "\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Tested Configuration: {config}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_configuration = config\n",
    "\n",
    "        print(f\"Current Best Accuracy: {best_accuracy * 100:.2f}% with Configuration: {best_configuration}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with configuration {config}: {e}\")\n",
    "\n",
    "print(f\"Final Best Configuration: {best_configuration}\")\n",
    "print(f\"Final Best Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-08-09T02:32:18.566898Z"
    }
   },
   "id": "3c0f2635fa312cff"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}, Accuracy: 25.58%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 5, 'filters': (128, 64, 512, 32, 256), 'dense_layers': 2, 'dense_units': (512, 128), 'dropout': 0.7, 'epochs': 45, 'batch_size': 16}, Accuracy: 9.30%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 3, 'filters': (128, 512, 32), 'dense_layers': 3, 'dense_units': (1024, 128, 2048), 'dropout': 0.7, 'epochs': 21, 'batch_size': 32}, Accuracy: 9.30%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "Tested Configuration: {'conv_layers': 3, 'filters': (256, 64, 512), 'dense_layers': 2, 'dense_units': (2048, 128), 'dropout': 0.7, 'epochs': 47, 'batch_size': 128}, Accuracy: 18.60%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x2d8944160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Tested Configuration: {'conv_layers': 2, 'filters': (512, 128), 'dense_layers': 3, 'dense_units': (512, 256, 1024), 'dropout': 0.7, 'epochs': 21, 'batch_size': 128}, Accuracy: 20.93%\n",
      "Current Best Accuracy: 25.58% with Configuration: {'conv_layers': 2, 'filters': (32, 128), 'dense_layers': 5, 'dense_units': (128, 1024, 256, 512, 2048), 'dropout': 0.4, 'epochs': 16, 'batch_size': 128}\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x292450d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Tested Configuration: {'conv_layers': 4, 'filters': (32, 64, 128, 256), 'dense_layers': 2, 'dense_units': (128, 2048), 'dropout': 0.4, 'epochs': 35, 'batch_size': 64}, Accuracy: 46.51%\n",
      "Current Best Accuracy: 46.51% with Configuration: {'conv_layers': 4, 'filters': (32, 64, 128, 256), 'dense_layers': 2, 'dense_units': (128, 2048), 'dropout': 0.4, 'epochs': 35, 'batch_size': 64}\n",
      "Tested Configuration: {'conv_layers': 1, 'filters': (32,), 'dense_layers': 2, 'dense_units': (1024, 256), 'dropout': 0.5, 'epochs': 22, 'batch_size': 128}, Accuracy: 34.88%\n",
      "Current Best Accuracy: 46.51% with Configuration: {'conv_layers': 4, 'filters': (32, 64, 128, 256), 'dense_layers': 2, 'dense_units': (128, 2048), 'dropout': 0.4, 'epochs': 35, 'batch_size': 64}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 137\u001B[0m\n\u001B[1;32m    134\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# Fit model using data augmentation with dynamic batch size\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatagen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mepochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m _, accuracy \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(X_test, y_test, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTested Configuration: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    313\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 314\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    315\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    316\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1498\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1500\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1505\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1506\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1508\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1509\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1510\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1514\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1515\u001B[0m   )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            image_file = os.path.join(folder, filename)\n",
    "            img = Image.open(image_file).convert('L')\n",
    "            img = img.resize((64, 64))  # Resize to 64x64 for consistency\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(img_array)\n",
    "            label_code = filename.split('.')[1][:2]\n",
    "            labels.append(label_map[label_code])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape for CNN input\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation with shear_range=0.2\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)  # Compute quantities required for featurewise normalization\n",
    "\n",
    "# Configuration generator function\n",
    "def generate_unique_configuration(history):\n",
    "    max_conv_layers = 10  # Increase the maximum number of convolutional layers\n",
    "    max_dense_layers = 5  # Increase the maximum number of dense layers\n",
    "    max_filters = [32, 64, 128, 256, 512]  # Add higher filter sizes\n",
    "    max_dense_units = [128, 256, 512, 1024, 2048]  # Increase dense layer units\n",
    "    max_dropout = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]  # Increase dropout options\n",
    "    epoch_range = (10, 50)  # Increase the range for epochs\n",
    "    batch_size_options = [16, 32, 64, 128]  # Possible batch sizes\n",
    "\n",
    "    while True:\n",
    "        conv_layers = random.randint(1, min(max_conv_layers, len(max_filters)))\n",
    "        dense_layers = random.randint(1, min(max_dense_layers, len(max_dense_units)))\n",
    "        filters = tuple(random.sample(max_filters, conv_layers))\n",
    "        dense_units = tuple(random.sample(max_dense_units, dense_layers))\n",
    "        dropout = random.choice(max_dropout)\n",
    "        epochs = random.randint(*epoch_range)  # Randomly choose epochs within the range\n",
    "        batch_size = random.choice(batch_size_options)  # Randomly select a batch size\n",
    "\n",
    "        config = {\n",
    "            'conv_layers': conv_layers,\n",
    "            'filters': filters,\n",
    "            'dense_layers': dense_layers,\n",
    "            'dense_units': dense_units,\n",
    "            'dropout': dropout,\n",
    "            'epochs': epochs,  # Include epochs in the configuration\n",
    "            'batch_size': batch_size  # Include batch size in the configuration\n",
    "        }\n",
    "\n",
    "        config_tuple = tuple(sorted((k, tuple(v) if isinstance(v, list) else v) for k, v in config.items()))\n",
    "\n",
    "        if config_tuple not in history:\n",
    "            history.add(config_tuple)\n",
    "            return config\n",
    "\n",
    "# Function to calculate the output size after Conv2D and MaxPooling\n",
    "def calculate_output_size(input_size, kernel_size, stride=1, padding='valid'):\n",
    "    if padding == 'same':\n",
    "        return input_size\n",
    "    return (input_size - kernel_size) // stride + 1\n",
    "\n",
    "# Generating and evaluating models\n",
    "history = set()\n",
    "best_accuracy = 0\n",
    "best_configuration = None\n",
    "\n",
    "for _ in range(10000):  # Generate and test 10,000 unique configurations\n",
    "    try:\n",
    "        config = generate_unique_configuration(history)\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(shape=(64, 64, 1)))  # Use 'shape' instead of 'input_shape'\n",
    "        input_size = 64  # Starting input size\n",
    "\n",
    "        for i in range(config['conv_layers']):\n",
    "            if calculate_output_size(input_size, 3) < 1:\n",
    "                raise ValueError(f\"Configuration {config} leads to an invalid layer size.\")\n",
    "\n",
    "            model.add(Conv2D(config['filters'][i], (3, 3), activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "            input_size = calculate_output_size(input_size, 2, stride=2)\n",
    "\n",
    "        model.add(Flatten())\n",
    "        for j in range(config['dense_layers']):\n",
    "            model.add(Dense(config['dense_units'][j], activation='relu'))\n",
    "        model.add(Dropout(config['dropout']))\n",
    "        model.add(Dense(len(np.unique(labels_encoded)), activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Fit model using data augmentation with dynamic batch size\n",
    "        model.fit(datagen.flow(X_train, y_train, batch_size=config['batch_size']), epochs=config['epochs'], verbose=0)\n",
    "\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Tested Configuration: {config}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_configuration = config\n",
    "\n",
    "        print(f\"Current Best Accuracy: {best_accuracy * 100:.2f}% with Configuration: {best_configuration}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with configuration {config}: {e}\")\n",
    "\n",
    "print(f\"Final Best Configuration: {best_configuration}\")\n",
    "print(f\"Final Best Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-09T13:40:22.952500Z",
     "start_time": "2024-08-09T13:11:31.139478Z"
    }
   },
   "id": "4a4ec5782c741577"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    # Set seed for data augmentation\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    # Ensure deterministic behavior in TensorFlow\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            image_file = os.path.join(folder, filename)\n",
    "            img = Image.open(image_file).convert('L')\n",
    "            img = img.resize((64, 64))  # Resize to 64x64 for consistency\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(img_array)\n",
    "            label_code = filename.split('.')[1][:2]\n",
    "            labels.append(label_map[label_code])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape for CNN input\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parameter combinations using itertools.product\n",
    "conv_layers_options = [1, 2]  # Number of convolutional layers\n",
    "filters_options = [32, 64]  # Number of filters\n",
    "dense_layers_options = [1, 2]  # Number of dense layers\n",
    "dense_units_options = [64, 128]  # Number of neurons in dense layers\n",
    "dropout_options = [0.1, 0.2]  # Dropout rates\n",
    "epochs_options = [50, 100]  # Number of epochs\n",
    "batch_size_options = [32, 64]  # Batch sizes\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Generate all configurations\n",
    "configurations = list(itertools.product(conv_layers_options, filters_options, dense_layers_options,\n",
    "                                        dense_units_options, dropout_options, epochs_options, batch_size_options))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_configuration = None\n",
    "\n",
    "for config in configurations:\n",
    "    conv_layers, filters, dense_layers, dense_units, dropout, epochs, batch_size = config\n",
    "    try:\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=(64, 64, 1)))\n",
    "\n",
    "        # Adding convolutional layers\n",
    "        for _ in range(conv_layers):\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # Adding dense layers\n",
    "        for _ in range(dense_layers):\n",
    "            model.add(Dense(dense_units, activation='relu'))\n",
    "\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Dense(len(np.unique(labels_encoded)), activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=epochs, verbose=0)\n",
    "\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_configuration = config\n",
    "\n",
    "        print(f\"Tested Configuration: {config}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with configuration {config}: {e}\")\n",
    "\n",
    "print(f\"Final Best Configuration: {best_configuration}\")\n",
    "print(f\"Final Best Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Final Best Configuration: (2, 32, 1, 128, 0.1, 100, 32)\n",
    "# Final Best Accuracy: 93.02%"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-09T16:22:55.317738Z"
    }
   },
   "id": "3a490763a35fc0d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 32, 0.001), Accuracy: 46.51%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 32, 0.002), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 32, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 32, 0.01), Accuracy: 60.47%\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x28ab87a30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 64, 0.001), Accuracy: 53.49%\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x2a0cd7910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 64, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 32, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 32, 0.002), Accuracy: 60.47%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 32, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 64, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 64, 0.002), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 64, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.1, 100, 64, 0.01), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 32, 0.001), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 32, 0.002), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 32, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 64, 0.001), Accuracy: 55.81%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 64, 0.002), Accuracy: 58.14%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 64, 0.005), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 50, 64, 0.01), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 32, 0.001), Accuracy: 39.53%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 32, 0.002), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 32, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 64, 0.001), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 64, 0.002), Accuracy: 23.26%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 64, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.2, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 32, 0.001), Accuracy: 37.21%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 32, 0.002), Accuracy: 58.14%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 32, 0.005), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 32, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 64, 0.001), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 64, 0.002), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 64, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 32, 0.001), Accuracy: 60.47%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 32, 0.002), Accuracy: 55.81%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 32, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 32, 0.01), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 64, 0.001), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 64, 0.002), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 64, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 1, 64, 0.3, 100, 64, 0.01), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 32, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 32, 0.005), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 64, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 50, 64, 0.01), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 32, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 32, 0.002), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 32, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 32, 0.01), Accuracy: 65.12%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 64, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 64, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 64, 0.005), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.1, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 32, 0.001), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 32, 0.002), Accuracy: 90.70%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 32, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 64, 0.001), Accuracy: 60.47%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 64, 0.005), Accuracy: 53.49%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 32, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 32, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 32, 0.01), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 64, 0.005), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.2, 100, 64, 0.01), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 32, 0.001), Accuracy: 65.12%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 32, 0.005), Accuracy: 51.16%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 32, 0.01), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 64, 0.001), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 64, 0.002), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 64, 0.005), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 32, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 64, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 64, 0.005), Accuracy: 90.70%\n",
      "Tested Configuration: (1, 32, 1, 128, 0.3, 100, 64, 0.01), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 32, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 32, 0.002), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 64, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 64, 0.002), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 64, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 32, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 32, 0.002), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 32, 0.005), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 64, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 64, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 64, 0.005), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.1, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 32, 0.001), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 32, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 32, 0.01), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 64, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 64, 0.002), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 64, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 32, 0.002), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 32, 0.005), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 64, 0.001), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 64, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.2, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 32, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 32, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 32, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 64, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 64, 0.002), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 64, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 32, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 32, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 64, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 64, 0.3, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 32, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 32, 0.01), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 64, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 32, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 32, 0.01), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 64, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 64, 0.002), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 64, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.1, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 32, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 32, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 32, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 32, 0.01), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 64, 0.002), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 64, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 32, 0.005), Accuracy: 90.70%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 64, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 64, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.2, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 32, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 32, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 32, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 32, 0.01), Accuracy: 11.63%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 64, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 64, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 50, 64, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 100, 32, 0.001), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 100, 32, 0.002), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 100, 32, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 100, 32, 0.01), Accuracy: 9.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 17:55:03.525237: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0] vs. [7]\n",
      "\t [[{{function_node __inference_one_step_on_data_618194}}{{node adam/truediv_15}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred with configuration (1, 32, 2, 128, 0.3, 100, 64, 0.001): Graph execution error:\n",
      "\n",
      "Detected at node adam/truediv_15 defined at (most recent call last):\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "\n",
      "  File \"/var/folders/nt/vmygtqvs10vb28qdjwspykv00000gn/T/ipykernel_33832/861005945.py\", line 109, in <module>\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 69, in train_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 147, in update_step\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/ops/numpy.py\", line 5502, in divide\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/sparse.py\", line 780, in sparse_wrapper\n",
      "\n",
      "  File \"/Users/arkamandol/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py\", line 2214, in divide\n",
      "\n",
      "Incompatible shapes: [0] vs. [7]\n",
      "\t [[{{node adam/truediv_15}}]] [Op:__inference_one_step_on_iterator_618261]\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 100, 64, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 32, 2, 128, 0.3, 100, 64, 0.01), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 32, 0.001), Accuracy: 41.86%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 32, 0.002), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 32, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 32, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 64, 0.001), Accuracy: 32.56%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 64, 0.002), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 64, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 50, 64, 0.01), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 32, 0.001), Accuracy: 48.84%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 32, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 64, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 64, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 64, 0.005), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.1, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 32, 0.001), Accuracy: 37.21%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 32, 0.002), Accuracy: 53.49%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 32, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 32, 0.01), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 64, 0.001), Accuracy: 48.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 18:27:57.626403: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:20025: Filling up shuffle buffer (this may take a while): 3 of 8\n",
      "2024-08-09 18:27:57.628187: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 64, 0.002), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 64, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 32, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 32, 0.002), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 32, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 64, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 64, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.2, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 32, 0.001), Accuracy: 65.12%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 32, 0.002), Accuracy: 20.93%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 32, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 32, 0.01), Accuracy: 60.47%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 64, 0.001), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 64, 0.002), Accuracy: 60.47%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 64, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 50, 64, 0.01), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 32, 0.001), Accuracy: 51.16%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 32, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 64, 0.001), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 64, 0.002), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 64, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 64, 0.3, 100, 64, 0.01), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 32, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 32, 0.005), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 64, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 64, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 64, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 50, 64, 0.01), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 32, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 32, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 32, 0.005), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 32, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 64, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.1, 100, 64, 0.01), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 32, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 32, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 32, 0.005), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 64, 0.001), Accuracy: 55.81%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 64, 0.005), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 50, 64, 0.01), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 32, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 64, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 64, 0.002), Accuracy: 90.70%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 64, 0.005), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.2, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 32, 0.001), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 32, 0.002), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 32, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 64, 0.001), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 64, 0.002), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 64, 0.005), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 50, 64, 0.01), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 32, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 32, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 32, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 64, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 64, 0.005), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 64, 1, 128, 0.3, 100, 64, 0.01), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 32, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 32, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 32, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 32, 0.01), Accuracy: 62.79%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 64, 0.001), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 64, 0.005), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 32, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 32, 0.002), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 64, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 64, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 64, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.1, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 32, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 32, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 32, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 64, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 32, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 64, 0.001), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 64, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.2, 100, 64, 0.01), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 32, 0.001), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 32, 0.002), Accuracy: 53.49%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 32, 0.005), Accuracy: 65.12%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 64, 0.001), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 64, 0.002), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 64, 0.005), Accuracy: 39.53%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 50, 64, 0.01), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 32, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 32, 0.005), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 64, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 64, 0.005), Accuracy: 67.44%\n",
      "Tested Configuration: (1, 64, 2, 64, 0.3, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 32, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 32, 0.002), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 32, 0.005), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 64, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 64, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 64, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 50, 64, 0.01), Accuracy: 72.09%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 32, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 32, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 64, 0.001), Accuracy: 86.05%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 64, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.1, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 32, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 32, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 32, 0.005), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 64, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 64, 0.005), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 50, 64, 0.01), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 32, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 32, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 32, 0.005), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 32, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 64, 0.001), Accuracy: 79.07%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 64, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 64, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.2, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 32, 0.001), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 32, 0.005), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 32, 0.01), Accuracy: 39.53%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 64, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 64, 0.005), Accuracy: 69.77%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 50, 64, 0.01), Accuracy: 13.95%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 32, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 32, 0.002), Accuracy: 81.40%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 32, 0.005), Accuracy: 90.70%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 64, 0.001), Accuracy: 76.74%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 64, 0.002), Accuracy: 83.72%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 64, 0.005), Accuracy: 88.37%\n",
      "Tested Configuration: (1, 64, 2, 128, 0.3, 100, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 32, 0.002), Accuracy: 74.42%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 32, 0.005), Accuracy: 83.72%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 64, 0.001), Accuracy: 74.42%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 64, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 64, 0.005), Accuracy: 67.44%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 50, 64, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 32, 0.001), Accuracy: 90.70%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 32, 0.005), Accuracy: 74.42%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 32, 0.01), Accuracy: 9.30%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 64, 0.001), Accuracy: 81.40%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 64, 0.002), Accuracy: 79.07%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 64, 0.005), Accuracy: 79.07%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.1, 100, 64, 0.01), Accuracy: 53.49%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.2, 50, 32, 0.001), Accuracy: 83.72%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.2, 50, 32, 0.002), Accuracy: 86.05%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.2, 50, 32, 0.005), Accuracy: 76.74%\n",
      "Tested Configuration: (2, 32, 1, 64, 0.2, 50, 32, 0.01), Accuracy: 65.12%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seeds(seed=1):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "# Define the path to the dataset folder\n",
    "dataset_folder = '/Users/Downloads/linda/JAFFE Dataset'\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {\n",
    "        \"AN\": \"anger\",\n",
    "        \"DI\": \"disgust\",\n",
    "        \"FE\": \"fear\",\n",
    "        \"HA\": \"happiness\",\n",
    "        \"SA\": \"sadness\",\n",
    "        \"SU\": \"surprise\",\n",
    "        \"NE\": \"neutral\"\n",
    "    }\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.tiff'):\n",
    "            image_file = os.path.join(folder, filename)\n",
    "            img = Image.open(image_file).convert('L')\n",
    "            img = img.resize((64, 64))  # Resize to 64x64 for consistency\n",
    "            img_array = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "            images.append(img_array)\n",
    "            label_code = filename.split('.')[1][:2]\n",
    "            labels.append(label_map[label_code])\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_images_and_labels(dataset_folder)\n",
    "images = images.reshape(-1, 64, 64, 1)  # Reshape for CNN input\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Parameter combinations using itertools.product\n",
    "conv_layers_options = [1, 2, 3]\n",
    "filters_options = [32, 64]\n",
    "dense_layers_options = [1, 2]\n",
    "dense_units_options = [64, 128]\n",
    "dropout_options = [0.1, 0.2, 0.3]\n",
    "epochs_options = [50, 100]\n",
    "batch_size_options = [32, 64]\n",
    "learning_rate_options = [0.001, 0.002, 0.005, 0.01]  # Different learning rates\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(shear_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Generate all configurations\n",
    "configurations = list(itertools.product(conv_layers_options, filters_options, dense_layers_options,\n",
    "                                        dense_units_options, dropout_options, epochs_options,\n",
    "                                        batch_size_options, learning_rate_options))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_configuration = None\n",
    "\n",
    "for config in configurations:\n",
    "    conv_layers, filters, dense_layers, dense_units, dropout, epochs, batch_size, learning_rate = config\n",
    "    try:\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer(input_shape=(64, 64, 1)))\n",
    "\n",
    "        # Adding convolutional layers\n",
    "        for _ in range(conv_layers):\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # Adding dense layers\n",
    "        for _ in range(dense_layers):\n",
    "            model.add(Dense(dense_units, activation='relu'))\n",
    "\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Dense(len(np.unique(labels_encoded)), activation='softmax'))\n",
    "\n",
    "        # Define the optimizer with a custom learning rate\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=epochs, verbose=0)\n",
    "\n",
    "        _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_configuration = config\n",
    "\n",
    "        print(f\"Tested Configuration: {config}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with configuration {config}: {e}\")\n",
    "\n",
    "print(f\"Final Best Configuration: {best_configuration}\")\n",
    "print(f\"Final Best Accuracy: {best_accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-08-09T16:23:41.352302Z"
    }
   },
   "id": "ce29ebf50cbdd8e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6c0d3dfe83c1ba40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
